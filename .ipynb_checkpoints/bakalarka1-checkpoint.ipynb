{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [10:06:46] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('LXRb_ch25_curated_DW_2.csv')\n",
    "# copy raw data\n",
    "data_new = data.copy()\n",
    "data_new[\"Molecule\"] = [Chem.MolFromSmiles(mol) for mol in data[\"smiles\"]]\n",
    "\n",
    "#colmun['Molecule'] invert to binary systems\n",
    "data_new['bin'] = [np.array(AllChem.GetMorganFingerprintAsBitVect(i,2, nBits=1024)) for i in data_new['Molecule']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>potency</th>\n",
       "      <th>pec50</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C</td>\n",
       "      <td>CHEMBL1023</td>\n",
       "      <td>434.000</td>\n",
       "      <td>6.362510</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...</td>\n",
       "      <td>CHEMBL1089232</td>\n",
       "      <td>2805.000</td>\n",
       "      <td>5.569777</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...</td>\n",
       "      <td>CHEMBL1091034</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...</td>\n",
       "      <td>CHEMBL1091976</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...</td>\n",
       "      <td>CHEMBL1092952</td>\n",
       "      <td>79.430</td>\n",
       "      <td>7.100015</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles      chembl_id   potency  \\\n",
       "0   Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C     CHEMBL1023   434.000   \n",
       "1  CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...  CHEMBL1089232  2805.000   \n",
       "2  CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...  CHEMBL1091034     3.162   \n",
       "3  Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...  CHEMBL1091976     3.162   \n",
       "4  Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...  CHEMBL1092952    79.430   \n",
       "\n",
       "      pec50  category  \n",
       "0  6.362510    active  \n",
       "1  5.569777  inactive  \n",
       "2  8.500038    active  \n",
       "3  8.500038    active  \n",
       "4  7.100015    active  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9023956711255896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        5.0  0.918519   0.923611  0.912698  0.836310       0.923611   \n",
       "1        5.5  0.870370   0.873016  0.868056  0.740154       0.852713   \n",
       "2        6.0  0.800000   0.478261  0.966292  0.542414       0.880000   \n",
       "3        6.5  0.803704   0.187500  0.995146  0.362823       0.923077   \n",
       "4        7.0  0.881481   0.179487  1.000000  0.397050       1.000000   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       0.912698        0.087302        0.076389  \n",
       "1       0.886525        0.131944        0.126984  \n",
       "2       0.781818        0.033708        0.521739  \n",
       "3       0.797665        0.004854        0.812500  \n",
       "4       0.878327        0.000000        0.820513  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### classifikation model change thre and than i compare date for diferent thre\n",
    "#this model predict active/inactive compounds\n",
    "#case1\n",
    "def classification_model(thre):\n",
    "    random_state = 20\n",
    "\n",
    "\n",
    "    #add new columns, number of columns\n",
    "    data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "    data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "    #divided date for two sets: train and test\n",
    "    train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "    train, test = train.copy(), test.copy()\n",
    "    x_train = np.asarray([x for x in train['bin']])\n",
    "    x_test = np.asarray([x for x in test['bin']]) \n",
    "    y_train = np.asarray([y for y in train['category_new']])\n",
    "    y_test = np.asarray([y for y in test['category_new']])\n",
    "\n",
    "    #RandomForesrClassifier\n",
    "    crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    crf.fit(x_train,y_train)\n",
    "    \n",
    "    # prediction on test set\n",
    "    crf_predict = crf.predict(x_test)\n",
    "\n",
    "    #CLassification:\n",
    "       #accuracy, spe, sen, MCC,\n",
    "        #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "    #confusion_matrix\n",
    "    #print(\"Confusion_matrix for test set:\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, crf_predict)\n",
    "    #print(conf_matrix)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    #print(\"\\n\")\n",
    "    #print(df)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    #Accuracy\n",
    "    #print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "    #print(\"\\n\")\n",
    "    #print(\"=== Classification Report ===\")\n",
    "    #print(classification_report(y_test, crf_predict))\n",
    "\n",
    "    # Performance metrics\n",
    "    errors = abs(crf_predict - y_test)\n",
    "    #print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    #MCC\n",
    "    MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    #put data for pandas data_out\n",
    "    try:\n",
    "        da = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "          'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        dff = pd.DataFrame(data=da)\n",
    "\n",
    "        data_out = data_out.append(dff, ignore_index = True)\n",
    "        data_out.drop_duplicates(keep='first', inplace=True)\n",
    "    except:\n",
    "        da = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "          'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "        data_out = pd.DataFrame(data=da)\n",
    "        da = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "          'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        dff = pd.DataFrame(data=da)\n",
    "\n",
    "        data_out = data_out.append(dff, ignore_index = True)\n",
    "        data_out.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "    #print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n",
    "    return data_out\n",
    "\n",
    "a1 = classification_model(5)\n",
    "a2 = classification_model(5.5)\n",
    "a3 = classification_model(6)\n",
    "a4 = classification_model(6.5)\n",
    "a5 = classification_model(7)\n",
    "frames = [ a1, a2, a3, a4, a5]\n",
    "data_out = pd.concat(frames)\n",
    "data_out.index = np.arange(len(data_out))\n",
    "display(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_csv('data_out_diferent_threshold_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.814560</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.089286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.806321</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.114035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.787159</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.122642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.879557</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.077670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.821390</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.126316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.730218</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.727257</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.643308</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.218391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.837161</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.123596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.772660</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.158537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>0.556072</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.507246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.572631</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.487935</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.516822</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.596774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.367069</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.372146</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.433545</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868932</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.314187</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.248081</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.512383</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.275647</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  N_Split  Split  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0         5.0      5.0    0.0  0.907407   0.910714  0.903846  0.814560   \n",
       "1         5.0      5.0    1.0  0.902778   0.885965  0.921569  0.806321   \n",
       "2         5.0      5.0    2.0  0.893519   0.877358  0.909091  0.787159   \n",
       "3         5.0      5.0    3.0  0.939815   0.922330  0.955752  0.879557   \n",
       "4         5.0      5.0    4.0  0.912037   0.873684  0.942149  0.821390   \n",
       "5         5.5      5.0    0.0  0.865741   0.860000  0.870690  0.730218   \n",
       "6         5.5      5.0    1.0  0.865741   0.842105  0.884298  0.727257   \n",
       "7         5.5      5.0    2.0  0.828704   0.781609  0.860465  0.643308   \n",
       "8         5.5      5.0    3.0  0.921296   0.876404  0.952756  0.837161   \n",
       "9         5.5      5.0    4.0  0.893519   0.841463  0.925373  0.772660   \n",
       "10        6.0      5.0    0.0  0.787037   0.416667  0.972222  0.503382   \n",
       "11        6.0      5.0    1.0  0.814815   0.492754  0.965986  0.556072   \n",
       "12        6.0      5.0    2.0  0.824074   0.558824  0.945946  0.572631   \n",
       "13        6.0      5.0    3.0  0.800926   0.390625  0.973684  0.487935   \n",
       "14        6.0      5.0    4.0  0.814815   0.403226  0.980519  0.516822   \n",
       "15        6.5      5.0    0.0  0.805556   0.196078  0.993939  0.367069   \n",
       "16        6.5      5.0    1.0  0.819444   0.152174  1.000000  0.351821   \n",
       "17        6.5      5.0    2.0  0.810185   0.200000  0.993976  0.372146   \n",
       "18        6.5      5.0    3.0  0.870370   0.250000  0.994444  0.433545   \n",
       "19        6.5      5.0    4.0  0.856481   0.222222  0.983333  0.348452   \n",
       "20        7.0      5.0    0.0  0.884259   0.193548  1.000000  0.412925   \n",
       "21        7.0      5.0    1.0  0.888889   0.148148  0.994709  0.314187   \n",
       "22        7.0      5.0    2.0  0.875000   0.103448  0.994652  0.248081   \n",
       "23        7.0      5.0    3.0  0.939815   0.333333  0.994949  0.512383   \n",
       "24        7.0      5.0    4.0  0.907407   0.200000  0.979592  0.275647   \n",
       "\n",
       "    Positive pred  Negative pred  False positive  False negative  \n",
       "0        0.910714       0.903846        0.096154        0.089286  \n",
       "1        0.926606       0.878505        0.078431        0.114035  \n",
       "2        0.902913       0.884956        0.090909        0.122642  \n",
       "3        0.950000       0.931034        0.044248        0.077670  \n",
       "4        0.922222       0.904762        0.057851        0.126316  \n",
       "5        0.851485       0.878261        0.129310        0.140000  \n",
       "6        0.851064       0.877049        0.115702        0.157895  \n",
       "7        0.790698       0.853846        0.139535        0.218391  \n",
       "8        0.928571       0.916667        0.047244        0.123596  \n",
       "9        0.873418       0.905109        0.074627        0.158537  \n",
       "10       0.882353       0.769231        0.027778        0.583333  \n",
       "11       0.871795       0.802260        0.034014        0.507246  \n",
       "12       0.826087       0.823529        0.054054        0.441176  \n",
       "13       0.862069       0.791444        0.026316        0.609375  \n",
       "14       0.892857       0.803191        0.019481        0.596774  \n",
       "15       0.909091       0.800000        0.006061        0.803922  \n",
       "16       1.000000       0.813397        0.000000        0.847826  \n",
       "17       0.909091       0.804878        0.006024        0.800000  \n",
       "18       0.900000       0.868932        0.005556        0.750000  \n",
       "19       0.727273       0.863415        0.016667        0.777778  \n",
       "20       1.000000       0.880952        0.000000        0.806452  \n",
       "21       0.800000       0.890995        0.005291        0.851852  \n",
       "22       0.750000       0.877358        0.005348        0.896552  \n",
       "23       0.857143       0.942584        0.005051        0.666667  \n",
       "24       0.500000       0.923077        0.020408        0.800000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "def classification_cross_validation(thre):\n",
    "    n_splits = 5\n",
    "\n",
    "    random_state = 20\n",
    "\n",
    "    data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "    data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "    cros_x = np.asarray([x for x in data_new['bin']])\n",
    "    cros_y = np.asarray([y for y in data_new['category_new']])\n",
    "    scores = cross_val_score(crf, cros_x, cros_y, cv=n_splits)\n",
    "   # print(\"Cross_validation_score\", scores)\n",
    "    #Cross Validation\n",
    "    #print(\"Cross validation:\")\n",
    "    kf = KFold(n_splits = n_splits, shuffle=True, random_state=random_state)\n",
    "    a = -1   \n",
    "        \n",
    "    for trains, tests in kf.split(cros_x, cros_y):\n",
    "        a = a+1\n",
    "      #  print('Number of split:', a)\n",
    "        rfc = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "        rfc.fit(cros_x[trains],cros_y[trains])\n",
    "      #  print(\"Accuracy:\",metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests])))\n",
    "        rfc_predict = rfc.predict(cros_x[tests])\n",
    "    \n",
    "        conf_matrix = confusion_matrix(cros_y[tests], rfc_predict)\n",
    "    \n",
    "       # print(conf_matrix)\n",
    "    \n",
    "        accur = metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests]))\n",
    "        if(accur == 1):\n",
    "            ACC = 1\n",
    "            TPR = 1\n",
    "            TNR = 1\n",
    "            MCC = 1\n",
    "            PPV = 1\n",
    "            NPV = 1\n",
    "            FPR = 1\n",
    "            FNR = 1\n",
    "            FDR = 1\n",
    "        else:\n",
    "            TN, FP, FN, TP = conf_matrix.ravel()\n",
    "            # Sensitivity, hit rate, recall, or true positive rate\n",
    "            TPR = TP/(TP+FN)\n",
    "            # Specificity or true negative rate\n",
    "            TNR = TN/(TN+FP)\n",
    "            #MCC\n",
    "            MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "            # Precision or positive predictive value\n",
    "            PPV = TP/(TP+FP)\n",
    "            # Negative predictive value\n",
    "            NPV = TN/(TN+FN)\n",
    "            # Fall out or false positive rate\n",
    "            FPR = FP/(FP+TN)\n",
    "            # False negative rate\n",
    "            FNR = FN/(TP+FN)\n",
    "            # False discovery rate\n",
    "            FDR = FP/(TP+FP)\n",
    "            # Overall accuracy\n",
    "            ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    \n",
    "        #put data for pandas data_out   \n",
    "        try:\n",
    "            dat = {'threshold': [thre],'N_Split':[n_splits],'Split':[a],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "                'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "            daf = pd.DataFrame(data=dat)\n",
    "        \n",
    "            data_vystup = data_vystup.append(daf, ignore_index = True)\n",
    "            data_vystup.drop_duplicates(keep='first', inplace=True) \n",
    "        except:\n",
    "       \n",
    "            dat = {'threshold': [],'N_Split':[], 'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "              'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "            data_vystup = pd.DataFrame(data=dat)\n",
    "            dat = {'threshold': [thre],'N_Split':[n_splits],'Split':[a],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "                'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "            daf = pd.DataFrame(data=dat)\n",
    "        \n",
    "            data_vystup = data_vystup.append(daf, ignore_index = True)\n",
    "            data_vystup.drop_duplicates(keep='first', inplace=True) \n",
    "    return data_vystup\n",
    "        \n",
    "a1 = classification_cross_validation(5)\n",
    "a2 = classification_cross_validation(5.5)\n",
    "a3 = classification_cross_validation(6)\n",
    "a4 = classification_cross_validation(6.5)\n",
    "a5 = classification_cross_validation(7)\n",
    "frames = [ a1, a2, a3, a4, a5]\n",
    "data_vystup = pd.concat(frames)\n",
    "data_vystup.index = np.arange(len(data_vystup))\n",
    "display(data_vystup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vystup.to_csv('vystup_Nsplits5_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table when you see old pec50 and new pec50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pec50</th>\n",
       "      <th>pec50_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.362510</td>\n",
       "      <td>5.806693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.569777</td>\n",
       "      <td>5.851192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.500038</td>\n",
       "      <td>7.247905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.500038</td>\n",
       "      <td>7.151196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.100015</td>\n",
       "      <td>7.103867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>6.769551</td>\n",
       "      <td>6.182987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>7.094076</td>\n",
       "      <td>5.998179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>5.761954</td>\n",
       "      <td>4.344674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>4.170761</td>\n",
       "      <td>4.310835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>6.543634</td>\n",
       "      <td>5.986237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pec50  pec50_new\n",
       "0     6.362510   5.806693\n",
       "1     5.569777   5.851192\n",
       "2     8.500038   7.247905\n",
       "3     8.500038   7.151196\n",
       "4     7.100015   7.103867\n",
       "...        ...        ...\n",
       "1075  6.769551   6.182987\n",
       "1076  7.094076   5.998179\n",
       "1077  5.761954   4.344674\n",
       "1078  4.170761   4.310835\n",
       "1079  6.543634   5.986237\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor score: 0.7140891324409928\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Regresion model\n",
    "#case2.1\n",
    "\n",
    "random_state = 20\n",
    "train_reg, test_reg = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train_reg, test_reg = train.copy(), test.copy()\n",
    "\n",
    "data_new_reg = [i for i in data_new['bin']]\n",
    "\n",
    "\n",
    "x_train_reg = [f for f in train_reg['bin']]\n",
    "x_test_reg = [f for f in test_reg['bin']]\n",
    "y_train_reg = [a for a in train_reg['pec50']]\n",
    "y_test_reg = [a for a in test_reg['pec50']]\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=101,max_depth=4, random_state=random_state)\n",
    "rfr.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "y_pred = rfr.predict(x_test_reg)\n",
    "sns.scatterplot(x=y_test_reg, y=y_pred)\n",
    "\n",
    "y_pred = rfr.predict(data_new_reg)\n",
    "data_new['pec50_new'] = y_pred\n",
    "\n",
    "df = pd.DataFrame({'pec50':[], 'pec50_new':[]})\n",
    "df['pec50'] = data_new['pec50']\n",
    "df['pec50_new'] = data_new['pec50_new']\n",
    "print(\"Table when you see old pec50 and new pec50\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "print(\"Regressor score:\", rfr.score(x_test_reg, y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        5.0  0.970370   0.959459  0.983607  0.940776       0.986111   \n",
       "1        5.5  0.966667   0.944828  0.992000  0.934485       0.992754   \n",
       "2        6.0  0.870370   0.722222  0.969136  0.734028       0.939759   \n",
       "3        6.5  0.955556   0.538462  1.000000  0.716395       1.000000   \n",
       "4        7.0  0.985185   0.700000  0.996154  0.775347       0.875000   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       0.952381        0.016393        0.040541  \n",
       "1       0.939394        0.008000        0.055172  \n",
       "2       0.839572        0.030864        0.277778  \n",
       "3       0.953125        0.000000        0.461538  \n",
       "4       0.988550        0.003846        0.300000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create classification model after reggresion model\n",
    "#case2.2s\n",
    "def classification_after_regression(thre):\n",
    "    random_state = 20\n",
    "\n",
    "\n",
    "    #add new column\n",
    "    data_new['category_new_reg'] = np.where(data_new['pec50_new']>=thre, 1, 0)\n",
    " \n",
    "\n",
    "    #divided date for two sets: train and test\n",
    "    train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "    train, test = train.copy(), test.copy()\n",
    "    x_train = np.asarray([x for x in train['bin']])\n",
    "    x_test = np.asarray([x for x in test['bin']]) \n",
    "    y_train = np.asarray([y for y in train['category_new_reg']])\n",
    "    y_test = np.asarray([y for y in test['category_new_reg']])\n",
    "\n",
    "    #RandomForesrClassifier\n",
    "    crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    crf.fit(x_train,y_train)\n",
    "\n",
    "    # prediction on test set\n",
    "    crf_predict = crf.predict(x_test)\n",
    "\n",
    "    #CLassification:\n",
    "       #accuracy, spe, sen, MCC,\n",
    "        #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "    #confusion_matrix\n",
    "    #print(\"Confusion_matrix for test set:\")\n",
    "    conf_matrix = confusion_matrix(y_test, crf_predict)\n",
    "   # print(conf_matrix)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    #print(\"\\n\")\n",
    "    #print(df)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    #Accuracy\n",
    "    #print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "    #print(\"\\n\")\n",
    "    #print(\"=== Classification Report ===\")\n",
    "    #print(classification_report(y_test, crf_predict))\n",
    "\n",
    "    # Performance metrics\n",
    "    errors = abs(crf_predict - y_test)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    #MCC\n",
    "    MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    #put data for pandas data_out\n",
    "    try:\n",
    "        dda = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "          'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        ddff = pd.DataFrame(data=dda)\n",
    "\n",
    "        data_out_reg = data_out_reg.append(ddff, ignore_index = True)\n",
    "        data_out_reg.drop_duplicates(keep='first', inplace=True)\n",
    "    except:\n",
    "        dda = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "          'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "        data_out_reg = pd.DataFrame(data=dda)\n",
    "        dda = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "          'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        ddff = pd.DataFrame(data=dda)\n",
    "\n",
    "        data_out_reg = data_out_reg.append(ddff, ignore_index = True)\n",
    "        data_out_reg.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "    false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "    #print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n",
    "    return data_out_reg\n",
    "a1 = classification_after_regression(5)\n",
    "a2 = classification_after_regression(5.5)\n",
    "a3 = classification_after_regression(6)\n",
    "a4 = classification_after_regression(6.5)\n",
    "a5 = classification_after_regression(7)\n",
    "frames = [ a1, a2, a3, a4, a5]\n",
    "data_out_reg = pd.concat(frames)\n",
    "data_out_reg.index = np.arange(len(data_out_reg))\n",
    "display(data_out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_reg.to_csv('data_out_reg_diferentthreshold_clasification_modelafter_reg.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for classifikation model(step 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        5.0  0.918519   0.923611  0.912698  0.836310   \n",
       "1           1        5.5  0.870370   0.873016  0.868056  0.740154   \n",
       "2           2        6.0  0.800000   0.478261  0.966292  0.542414   \n",
       "3           3        6.5  0.803704   0.187500  0.995146  0.362823   \n",
       "4           4        7.0  0.881481   0.179487  1.000000  0.397050   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.923611       0.912698        0.087302        0.076389  \n",
       "1       0.852713       0.886525        0.131944        0.126984  \n",
       "2       0.880000       0.781818        0.033708        0.521739  \n",
       "3       0.923077       0.797665        0.004854        0.812500  \n",
       "4       1.000000       0.878327        0.000000        0.820513  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_diferent_threshold_clasification_model.csv')\n",
    "print(\"Data for classifikation model(step 1)\")\n",
    "data_clas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after croos validation for classification model (step1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.814560</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.089286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.806321</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.114035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.787159</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.122642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.879557</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.077670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.821390</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.126316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.730218</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.727257</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.643308</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.218391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.837161</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.123596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.772660</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.158537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.503382</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>0.556072</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.507246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.572631</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.487935</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.516822</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.596774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.367069</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.372146</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.433545</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868932</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.314187</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.248081</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.512383</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.275647</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  threshold  N_Split  Split  Accuracy  Sensitiv.   Specif.  \\\n",
       "0            0        5.0      5.0    0.0  0.907407   0.910714  0.903846   \n",
       "1            1        5.0      5.0    1.0  0.902778   0.885965  0.921569   \n",
       "2            2        5.0      5.0    2.0  0.893519   0.877358  0.909091   \n",
       "3            3        5.0      5.0    3.0  0.939815   0.922330  0.955752   \n",
       "4            4        5.0      5.0    4.0  0.912037   0.873684  0.942149   \n",
       "5            5        5.5      5.0    0.0  0.865741   0.860000  0.870690   \n",
       "6            6        5.5      5.0    1.0  0.865741   0.842105  0.884298   \n",
       "7            7        5.5      5.0    2.0  0.828704   0.781609  0.860465   \n",
       "8            8        5.5      5.0    3.0  0.921296   0.876404  0.952756   \n",
       "9            9        5.5      5.0    4.0  0.893519   0.841463  0.925373   \n",
       "10          10        6.0      5.0    0.0  0.787037   0.416667  0.972222   \n",
       "11          11        6.0      5.0    1.0  0.814815   0.492754  0.965986   \n",
       "12          12        6.0      5.0    2.0  0.824074   0.558824  0.945946   \n",
       "13          13        6.0      5.0    3.0  0.800926   0.390625  0.973684   \n",
       "14          14        6.0      5.0    4.0  0.814815   0.403226  0.980519   \n",
       "15          15        6.5      5.0    0.0  0.805556   0.196078  0.993939   \n",
       "16          16        6.5      5.0    1.0  0.819444   0.152174  1.000000   \n",
       "17          17        6.5      5.0    2.0  0.810185   0.200000  0.993976   \n",
       "18          18        6.5      5.0    3.0  0.870370   0.250000  0.994444   \n",
       "19          19        6.5      5.0    4.0  0.856481   0.222222  0.983333   \n",
       "20          20        7.0      5.0    0.0  0.884259   0.193548  1.000000   \n",
       "21          21        7.0      5.0    1.0  0.888889   0.148148  0.994709   \n",
       "22          22        7.0      5.0    2.0  0.875000   0.103448  0.994652   \n",
       "23          23        7.0      5.0    3.0  0.939815   0.333333  0.994949   \n",
       "24          24        7.0      5.0    4.0  0.907407   0.200000  0.979592   \n",
       "\n",
       "         MCC  Positive pred  Negative pred  False positive  False negative  \n",
       "0   0.814560       0.910714       0.903846        0.096154        0.089286  \n",
       "1   0.806321       0.926606       0.878505        0.078431        0.114035  \n",
       "2   0.787159       0.902913       0.884956        0.090909        0.122642  \n",
       "3   0.879557       0.950000       0.931034        0.044248        0.077670  \n",
       "4   0.821390       0.922222       0.904762        0.057851        0.126316  \n",
       "5   0.730218       0.851485       0.878261        0.129310        0.140000  \n",
       "6   0.727257       0.851064       0.877049        0.115702        0.157895  \n",
       "7   0.643308       0.790698       0.853846        0.139535        0.218391  \n",
       "8   0.837161       0.928571       0.916667        0.047244        0.123596  \n",
       "9   0.772660       0.873418       0.905109        0.074627        0.158537  \n",
       "10  0.503382       0.882353       0.769231        0.027778        0.583333  \n",
       "11  0.556072       0.871795       0.802260        0.034014        0.507246  \n",
       "12  0.572631       0.826087       0.823529        0.054054        0.441176  \n",
       "13  0.487935       0.862069       0.791444        0.026316        0.609375  \n",
       "14  0.516822       0.892857       0.803191        0.019481        0.596774  \n",
       "15  0.367069       0.909091       0.800000        0.006061        0.803922  \n",
       "16  0.351821       1.000000       0.813397        0.000000        0.847826  \n",
       "17  0.372146       0.909091       0.804878        0.006024        0.800000  \n",
       "18  0.433545       0.900000       0.868932        0.005556        0.750000  \n",
       "19  0.348452       0.727273       0.863415        0.016667        0.777778  \n",
       "20  0.412925       1.000000       0.880952        0.000000        0.806452  \n",
       "21  0.314187       0.800000       0.890995        0.005291        0.851852  \n",
       "22  0.248081       0.750000       0.877358        0.005348        0.896552  \n",
       "23  0.512383       0.857143       0.942584        0.005051        0.666667  \n",
       "24  0.275647       0.500000       0.923077        0.020408        0.800000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_cros = pd.read_csv('/home/valeriia/bakalarka/bakalarka/vystup_Nsplits5_clasification_model.csv')\n",
    "print(\"Data after croos validation for classification model (step1)\")\n",
    "data_clas_cros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data classifikation(which i built after regresion model)(step 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        5.0  0.970370   0.959459  0.983607  0.940776   \n",
       "1           1        5.5  0.966667   0.944828  0.992000  0.934485   \n",
       "2           2        6.0  0.870370   0.722222  0.969136  0.734028   \n",
       "3           3        6.5  0.955556   0.538462  1.000000  0.716395   \n",
       "4           4        7.0  0.985185   0.700000  0.996154  0.775347   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.986111       0.952381        0.016393        0.040541  \n",
       "1       0.992754       0.939394        0.008000        0.055172  \n",
       "2       0.939759       0.839572        0.030864        0.277778  \n",
       "3       1.000000       0.953125        0.000000        0.461538  \n",
       "4       0.875000       0.988550        0.003846        0.300000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_reg = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_reg_diferentthreshold_clasification_modelafter_reg.csv')\n",
    "print(\"Data classifikation(which i built after regresion model)(step 2)\")\n",
    "data_clas_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW KOD:\n",
    "#end table\n",
    "\n",
    "data = pd.read_csv('/home/valeriia/bakalarka/bakalarka/LXRb_ch25_curated_DW_2.csv')\n",
    "# copy raw data\n",
    "data_new_2 = data.copy()\n",
    "data_new_2[\"Molecule\"] = [Chem.MolFromSmiles(mol) for mol in data[\"smiles\"]]\n",
    "\n",
    "#colmun['Molecule'] invert to binary systems\n",
    "data_new_2['bin'] = [np.array(AllChem.GetMorganFingerprintAsBitVect(i,2, nBits=1024)) for i in data_new_2['Molecule']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pomoc = {'Case':[],'threshold': [],'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[]}\n",
    "data_out_end = pd.DataFrame(data=pomoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.806321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.787159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.879557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.821390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.963587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.891401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.954743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.898803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.881086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.727257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.643308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.837161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.772660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.918666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.918680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.926430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.945491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>0.556072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.572631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.487935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.516822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.816109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.679373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.804884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.772789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.786912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.372146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.433545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.348452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.759257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961353</td>\n",
       "      <td>0.713408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.781768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975369</td>\n",
       "      <td>0.839305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.824451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.314187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.248081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.512383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.275647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.812636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.698679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.703795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.923613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.933174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  threshold  Split  Accuracy  Sensitiv.   Specif.       MCC\n",
       "0    1.0        5.0    1.0  0.902778   0.885965  0.921569  0.806321\n",
       "1    1.0        5.0    2.0  0.893519   0.877358  0.909091  0.787159\n",
       "2    1.0        5.0    3.0  0.939815   0.922330  0.955752  0.879557\n",
       "3    1.0        5.0    4.0  0.912037   0.873684  0.942149  0.821390\n",
       "4    2.2        5.0    0.0  0.981481   1.000000  0.962264  0.963587\n",
       "5    2.2        5.0    1.0  0.944444   0.981308  0.908257  0.891401\n",
       "6    2.2        5.0    2.0  0.976852   1.000000  0.955357  0.954743\n",
       "7    2.2        5.0    3.0  0.949074   0.969697  0.931624  0.898803\n",
       "8    2.2        5.0    4.0  0.939815   0.977778  0.912698  0.881086\n",
       "9    1.0        5.5    1.0  0.865741   0.842105  0.884298  0.727257\n",
       "10   1.0        5.5    2.0  0.828704   0.781609  0.860465  0.643308\n",
       "11   1.0        5.5    3.0  0.921296   0.876404  0.952756  0.837161\n",
       "12   1.0        5.5    4.0  0.893519   0.841463  0.925373  0.772660\n",
       "13   2.2        5.5    0.0  0.958333   0.990566  0.927273  0.918666\n",
       "14   2.2        5.5    1.0  0.958333   0.990476  0.927928  0.918680\n",
       "15   2.2        5.5    2.0  0.962963   0.980198  0.947826  0.926430\n",
       "16   2.2        5.5    3.0  0.972222   1.000000  0.950413  0.945491\n",
       "17   2.2        5.5    4.0  0.953704   0.965909  0.945312  0.905452\n",
       "18   1.0        6.0    1.0  0.814815   0.492754  0.965986  0.556072\n",
       "19   1.0        6.0    2.0  0.824074   0.558824  0.945946  0.572631\n",
       "20   1.0        6.0    3.0  0.800926   0.390625  0.973684  0.487935\n",
       "21   1.0        6.0    4.0  0.814815   0.403226  0.980519  0.516822\n",
       "22   2.2        6.0    0.0  0.916667   0.939394  0.906667  0.816109\n",
       "23   2.2        6.0    1.0  0.902778   0.960000  0.895288  0.679373\n",
       "24   2.2        6.0    2.0  0.907407   0.932432  0.894366  0.804884\n",
       "25   2.2        6.0    3.0  0.944444   1.000000  0.938462  0.772789\n",
       "26   2.2        6.0    4.0  0.949074   1.000000  0.943590  0.786912\n",
       "27   1.0        6.5    1.0  0.819444   0.152174  1.000000  0.351821\n",
       "28   1.0        6.5    2.0  0.810185   0.200000  0.993976  0.372146\n",
       "29   1.0        6.5    3.0  0.870370   0.250000  0.994444  0.433545\n",
       "30   1.0        6.5    4.0  0.856481   0.222222  0.983333  0.348452\n",
       "31   2.2        6.5    0.0  0.962963   1.000000  0.960784  0.759257\n",
       "32   2.2        6.5    1.0  0.962963   1.000000  0.961353  0.713408\n",
       "33   2.2        6.5    2.0  0.962963   1.000000  0.960396  0.781768\n",
       "34   2.2        6.5    3.0  0.976852   1.000000  0.975369  0.839305\n",
       "35   2.2        6.5    4.0  0.972222   0.937500  0.975000  0.824451\n",
       "36   1.0        7.0    1.0  0.888889   0.148148  0.994709  0.314187\n",
       "37   1.0        7.0    2.0  0.875000   0.103448  0.994652  0.248081\n",
       "38   1.0        7.0    3.0  0.939815   0.333333  0.994949  0.512383\n",
       "39   1.0        7.0    4.0  0.907407   0.200000  0.979592  0.275647\n",
       "40   2.2        7.0    0.0  0.990741   1.000000  0.990566  0.812636\n",
       "41   2.2        7.0    1.0  0.976852   1.000000  0.976303  0.698679\n",
       "42   2.2        7.0    2.0  0.990741   1.000000  0.990654  0.703795\n",
       "43   2.2        7.0    3.0  0.995370   1.000000  0.995238  0.923613\n",
       "44   2.2        7.0    4.0  0.995370   1.000000  0.995215  0.933174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#END table of all model\n",
    "def comparisons_of_all_models(thre):\n",
    "    n_splits = 5\n",
    "    random_state = 20\n",
    "    data_new_2['number'] = data_new_2['chembl_id'].rank(method='min')\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    data_new_2['number']= lab_enc.fit_transform(data_new_2['number'])\n",
    "    #category_new is column where have convert category(inactive/active) to (0,1)\n",
    "    data_new_2['category_new'] = np.where(data_new_2['pec50']>=thre, 1, 0)\n",
    "\n",
    "    kf = KFold(n_splits = n_splits, shuffle=True, random_state=random_state)\n",
    "    a = -1   \n",
    "       \n",
    "    for trains, tests in kf.split(data_new_2):\n",
    "        a = a+1\n",
    "        #print('Number of split:', a)\n",
    "        train = data_new_2.iloc[trains]\n",
    "        test = data_new_2.iloc[tests]\n",
    "        #clasification, i used bin and category new columns   \n",
    "        case = 1\n",
    "        x_train = np.asarray([x for x in train['bin']])\n",
    "        x_test = np.asarray([x for x in test['bin']]) \n",
    "        y_train = np.asarray([y for y in train['category_new']])\n",
    "        y_test = np.asarray([y for y in test['category_new']])\n",
    "    \n",
    "        rfc = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "        rfc.fit(x_train,y_train)\n",
    "        rfc_predict = rfc.predict(x_test)\n",
    "        conf_matrix = confusion_matrix(y_test, rfc_predict)\n",
    "        TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "        accur = metrics.accuracy_score(y_test, rfc.predict(x_test))\n",
    "        #print(accur)\n",
    "    \n",
    "        # Sensitivity\n",
    "        TPR = TP/(TP+FN)\n",
    "        # Specificity \n",
    "        TNR = TN/(TN+FP)\n",
    "        #MCC\n",
    "        MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    \n",
    "        try:\n",
    "            pomoc = {'Case':[case],'threshold': [thre],'Split':[a],'Accuracy':[accur], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC]}\n",
    "            df_table = pd.DataFrame(data=pomoc)\n",
    "\n",
    "            data_out_end = data_out_end.append(df_table, ignore_index = True)\n",
    "            data_out_end.drop_duplicates(keep='first', inplace=True)\n",
    "        except:\n",
    "            pomoc = {'Case':[],'threshold': [],'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[]}\n",
    "            data_out_end = pd.DataFrame(data=pomoc)\n",
    "\n",
    "        \n",
    "\n",
    "        #regresion i used bin and pec50  ?????\n",
    "        case = 2.1\n",
    "        x_train_reg = [f for f in train['bin']]\n",
    "        x_test_reg = [f for f in test['bin']]\n",
    "        y_train_reg = [a for a in train['pec50']]\n",
    "        y_test_reg = [a for a in test['pec50']]\n",
    "        data_new_reg = [i for i in data_new_2['bin']]\n",
    "        rfr = RandomForestRegressor(n_estimators=101,max_depth=4, random_state=random_state)\n",
    "        rfr.fit(x_train_reg, y_train_reg)\n",
    "        y_pred = rfr.predict(x_test_reg)\n",
    "        sns.scatterplot(x=y_test_reg, y=y_pred)\n",
    "\n",
    "        y_pred = rfr.predict(data_new_reg)\n",
    "        data_new_2['pec50_new'] = y_pred\n",
    "    \n",
    "    \n",
    "      \n",
    "        #classification after regresion i used bin and category_new_reg\n",
    "        case = 2.2\n",
    "        data_new_2['category_new_reg'] = np.where(data_new_2['pec50_new']>=thre, 1, 0)\n",
    "        train = data_new_2.iloc[trains]\n",
    "        test = data_new_2.iloc[tests]\n",
    "    \n",
    "        x_train_cl = np.asarray([x for x in train['bin']])\n",
    "        x_test_cl = np.asarray([x for x in test['bin']]) \n",
    "        y_train_cl = np.asarray([y for y in train['category_new_reg']])\n",
    "        y_test_cl = np.asarray([y for y in test['category_new_reg']])\n",
    "    \n",
    "        rfc_reg = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "        rfc_reg.fit(x_train_cl,y_train_cl)\n",
    "        rfc_reg_predict = rfc_reg.predict(x_test_cl)\n",
    "        conf_matrix = confusion_matrix(rfc_reg.predict(x_test_cl), y_test_cl)\n",
    "        #print(conf_matrix)\n",
    "    \n",
    "    \n",
    "        accur = metrics.accuracy_score(y_test_cl, rfc_reg.predict(x_test_cl))\n",
    "       # print(accur)\n",
    "        if(accur == 1):\n",
    "            TPR = 1\n",
    "            TNR = 1\n",
    "            MCC = 1\n",
    "        else:\n",
    "            TN, FP, FN, TP = conf_matrix.ravel()\n",
    "            # Sensitivity\n",
    "            TPR = TP/(TP+FN)\n",
    "            # Specificity \n",
    "            TNR = TN/(TN+FP)\n",
    "            #MCC\n",
    "            MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    \n",
    "        try:\n",
    "            pomoc = {'Case':[case],'threshold': [thre],'Split':[a],'Accuracy':[accur], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC]}\n",
    "            df_table = pd.DataFrame(data=pomoc)\n",
    "\n",
    "            data_out_end = data_out_end.append(df_table, ignore_index = True)\n",
    "            data_out_end.drop_duplicates(keep='first', inplace=True)\n",
    "        except:\n",
    "            pomoc = {'Case':[],'threshold': [],'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[]}\n",
    "            data_out_end = pd.DataFrame(data=pomoc)\n",
    "            \n",
    "    \n",
    "        data_out_end = data_out_end.sort_values(by=['Case', 'threshold', 'Split'])\n",
    "    #display(data_out_end)\n",
    "    return data_out_end\n",
    "    #display(data_out_end)\n",
    "\n",
    "a1 = comparisons_of_all_models(5)\n",
    "a2 = comparisons_of_all_models(5.5)\n",
    "a3 = comparisons_of_all_models(6)\n",
    "a4 = comparisons_of_all_models(6.5)\n",
    "a5 = comparisons_of_all_models(7)\n",
    "frames = [ a1, a2, a3, a4, a5]\n",
    "result = pd.concat(frames)\n",
    "result.index = np.arange(len(result))\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('data_out_end.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
