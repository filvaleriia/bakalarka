{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:11:00] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/valeriia/bakalarka/bakalarka/LXRb_ch25_curated_DW_2.csv')\n",
    "# copy raw data\n",
    "data_new = data.copy()\n",
    "data_new[\"Molecule\"] = [Chem.MolFromSmiles(mol) for mol in data[\"smiles\"]]\n",
    "\n",
    "#colmun['Molecule'] invert to binary systems\n",
    "data_new['bin'] = [np.array(AllChem.GetMorganFingerprintAsBitVect(i,2, nBits=1024)) for i in data_new['Molecule']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>potency</th>\n",
       "      <th>pec50</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C</td>\n",
       "      <td>CHEMBL1023</td>\n",
       "      <td>434.000</td>\n",
       "      <td>6.362510</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...</td>\n",
       "      <td>CHEMBL1089232</td>\n",
       "      <td>2805.000</td>\n",
       "      <td>5.569777</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...</td>\n",
       "      <td>CHEMBL1091034</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...</td>\n",
       "      <td>CHEMBL1091976</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...</td>\n",
       "      <td>CHEMBL1092952</td>\n",
       "      <td>79.430</td>\n",
       "      <td>7.100015</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles      chembl_id   potency  \\\n",
       "0   Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C     CHEMBL1023   434.000   \n",
       "1  CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...  CHEMBL1089232  2805.000   \n",
       "2  CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...  CHEMBL1091034     3.162   \n",
       "3  Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...  CHEMBL1091976     3.162   \n",
       "4  Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...  CHEMBL1092952    79.430   \n",
       "\n",
       "      pec50  category  \n",
       "0  6.362510    active  \n",
       "1  5.569777  inactive  \n",
       "2  8.500038    active  \n",
       "3  8.500038    active  \n",
       "4  7.100015    active  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9023956711255896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix for test set:\n",
      "[[115  11]\n",
      " [ 11 133]]\n",
      "\n",
      "\n",
      "            predicted+  predicted-\n",
      "0  actual+         133          11\n",
      "1  actual-          11         115\n",
      "\n",
      "\n",
      "Accuracy: 0.9185185185185185\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       126\n",
      "           1       0.92      0.92      0.92       144\n",
      "\n",
      "    accuracy                           0.92       270\n",
      "   macro avg       0.92      0.92      0.92       270\n",
      "weighted avg       0.92      0.92      0.92       270\n",
      "\n",
      "Average absolute error: 0.08 degrees.\n",
      "Sensitivity: 0.924\n",
      "Specifity: 0.913\n",
      "MMC: 0.836\n",
      "Positive predictive 0.924\n",
      "Negative predictive 0.913\n",
      "False positive 0.087\n",
      "False negative 0.076\n",
      "False discovery 0.076\n",
      "Overall accuracy 0.919\n",
      "roc_auc_score for RandomForestClassification:  0.9528\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9185185185185185"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### classifikation model change thre and than i compare date for diferent thre\n",
    "#this model predict active/inactive compounds\n",
    "random_state = 20\n",
    "thre = 5\n",
    "\n",
    "#add new columns, number of columns\n",
    "data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "#divided date for two sets: train and test\n",
    "train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train, test = train.copy(), test.copy()\n",
    "x_train = np.asarray([x for x in train['bin']])\n",
    "x_test = np.asarray([x for x in test['bin']]) \n",
    "y_train = np.asarray([y for y in train['category_new']])\n",
    "y_test = np.asarray([y for y in test['category_new']])\n",
    "\n",
    "#RandomForesrClassifier\n",
    "crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "crf.fit(x_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "crf_predict = crf.predict(x_test)\n",
    "\n",
    "#CLassification:\n",
    "   #accuracy, spe, sen, MCC,\n",
    "    #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "#confusion_matrix\n",
    "print(\"Confusion_matrix for test set:\")\n",
    "conf_matrix = confusion_matrix(crf.predict(x_test), y_test)\n",
    "print(conf_matrix)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(\"\\n\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "print(\"\\n\")\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, crf_predict))\n",
    "\n",
    "# Performance metrics\n",
    "errors = abs(crf_predict - y_test)\n",
    "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Sensitivity:\", round(TPR,3))\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(\"Specifity:\", round(TNR, 3))\n",
    "#MCC\n",
    "MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "print(\"MMC:\", round(MCC, 3))\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Positive predictive\", round(PPV,3))\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Negative predictive\", round(NPV,3))\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "print(\"False positive\", round(FPR,3))\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"False negative\", round(FNR,3))\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "print(\"False discovery\", round(FDR,3))\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Overall accuracy\", round(ACC,3))\n",
    "\n",
    "#put data for pandas data_out\n",
    "try:\n",
    "    da = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "      'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "    dff = pd.DataFrame(data=da)\n",
    "\n",
    "    data_out = data_out.append(dff, ignore_index = True)\n",
    "    data_out.drop_duplicates(keep='first', inplace=True)\n",
    "except:\n",
    "    daa = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "      'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "    data_out = pd.DataFrame(data=daa)\n",
    "\n",
    "\n",
    "\n",
    "y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n",
    "\n",
    "#PLOT ROC curves\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('ROC cuves')\n",
    "plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate(TP)')\n",
    "plt.xlabel('False Positive Rate(FP)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cross-validation\n",
    "crf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.202335</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        5.0  0.918519   0.923611  0.912698  0.836310       0.923611   \n",
       "1        5.5  0.870370   0.852713  0.886525  0.740154       0.873016   \n",
       "2        6.0  0.800000   0.880000  0.781818  0.542414       0.478261   \n",
       "3        6.5  0.803704   0.923077  0.797665  0.362823       0.187500   \n",
       "4        7.0  0.881481   1.000000  0.878327  0.397050       0.179487   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       0.912698        0.087302        0.076389  \n",
       "1       0.868056        0.113475        0.147287  \n",
       "2       0.966292        0.218182        0.120000  \n",
       "3       0.995146        0.202335        0.076923  \n",
       "4       1.000000        0.121673        0.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_csv('data_out_diferent_threshold_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross validation:\n",
      "Number of split: 0\n",
      "Accuracy: 0.9074074074074074\n",
      "[[98 10]\n",
      " [ 0  0]]\n",
      "[[98 10]\n",
      " [ 0  0]]\n",
      "ACC 0.9074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split: 1\n",
      "Accuracy: 1.0\n",
      "[[108]]\n",
      "Number of split: 2\n",
      "Accuracy: 1.0\n",
      "[[108]]\n",
      "Number of split: 3\n",
      "Accuracy: 0.9629629629629629\n",
      "[[104   4]\n",
      " [  0   0]]\n",
      "[[104   4]\n",
      " [  0   0]]\n",
      "ACC 0.9629629629629629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split: 4\n",
      "Accuracy: 0.8240740740740741\n",
      "[[89 19]\n",
      " [ 0  0]]\n",
      "[[89 19]\n",
      " [ 0  0]]\n",
      "ACC 0.8240740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split: 5\n",
      "Accuracy: 0.9444444444444444\n",
      "[[102   6]\n",
      " [  0   0]]\n",
      "[[102   6]\n",
      " [  0   0]]\n",
      "ACC 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split: 6\n",
      "Accuracy: 0.8981481481481481\n",
      "[[97 11]\n",
      " [ 0  0]]\n",
      "[[97 11]\n",
      " [ 0  0]]\n",
      "ACC 0.8981481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split: 7\n",
      "Accuracy: 0.7870370370370371\n",
      "[[76 22]\n",
      " [ 1  9]]\n",
      "[[76 22]\n",
      " [ 1  9]]\n",
      "ACC 0.7870370370370371\n",
      "Number of split: 8\n",
      "Accuracy: 0.8333333333333334\n",
      "[[83 16]\n",
      " [ 2  7]]\n",
      "[[83 16]\n",
      " [ 2  7]]\n",
      "ACC 0.8333333333333334\n",
      "Number of split: 9\n",
      "Accuracy: 0.8055555555555556\n",
      "[[87 21]\n",
      " [ 0  0]]\n",
      "[[87 21]\n",
      " [ 0  0]]\n",
      "ACC 0.8055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "thre = 7\n",
    "random_state = 20\n",
    "\n",
    "#add new columns, number of columns\n",
    "data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "#print(\"crf_score\", crf.score(x_test, y_test))\n",
    "cros_x = np.asarray([x for x in data_new['bin']])\n",
    "cros_y = np.asarray([y for y in data_new['category_new']])\n",
    "#scores = cross_val_score(crf, cros_x, cros_y, cv=n_splits)\n",
    "#print(\"Cross_val_scores\",scores)\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"\\n\")\n",
    "\n",
    "#Cross Validation\n",
    "print(\"Cross validation:\")\n",
    "kf = KFold(n_splits = n_splits)\n",
    "a = -1   \n",
    "        \n",
    "for trains, tests in kf.split(cros_x, cros_y):\n",
    "    \n",
    "    #RandomForesrClassifier\n",
    "    rfc = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    rfc.fit(cros_x[trains],cros_y[trains])\n",
    "\n",
    "    # prediction on test set\n",
    "    rfc_predict = rfc.predict(cros_x[tests])\n",
    "    #print(\"Predict\", rfc_predict)\n",
    "    \n",
    "    a = a+1\n",
    "    print('Number of split:', a)\n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests])))\n",
    "    rfc_predict = rfc.predict(cros_x[tests])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(rfc.predict(cros_x[tests]),\n",
    "                                   cros_y[tests])\n",
    "    print(conf_matrix)\n",
    "    acur = metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests]))\n",
    "    if(acur == 1.0):\n",
    "       \n",
    "        TPR = '-'\n",
    "        TNR ='-'\n",
    "        MCC ='-'\n",
    "        PPV = '-'\n",
    "        NPV = '-'\n",
    "        FPR = '-'\n",
    "        FNR = '-'\n",
    "        FDR = '-'\n",
    "        ACC = acur\n",
    "        \n",
    "    else:\n",
    "        TN, FP, FN, TP = conf_matrix.ravel()\n",
    "        \n",
    "        print(conf_matrix)\n",
    "    \n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = TP/(TP+FN)\n",
    "        #print(\"TPR\", TPR)\n",
    "        # Specificity or true negative rate\n",
    "        TNR = TN/(TN+FP)\n",
    "        #MCC\n",
    "        MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "        # Precision or positive predictive value\n",
    "        PPV = TP/(TP+FP)\n",
    "        # Negative predictive value\n",
    "        NPV = TN/(TN+FN)\n",
    "        # Fall out or false positive rate\n",
    "        FPR = FP/(FP+TN)\n",
    "        # False negative rate\n",
    "        FNR = FN/(TP+FN)\n",
    "        # False discovery rate\n",
    "        FDR = FP/(TP+FP)\n",
    "        # Overall accuracy\n",
    "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "        print(\"ACC\", ACC)\n",
    "    \n",
    "    #put data for pandas data_out   \n",
    "    try:\n",
    "        datt = {'threshold': [thre],'N_Split':[n_splits],'Split':[a],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "            'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        daf = pd.DataFrame(data=datt)\n",
    "        \n",
    "        data_vystup = data_vystup.append(daf, ignore_index = True)\n",
    "        data_vystup.drop_duplicates(keep='first', inplace=True) \n",
    "    except:\n",
    "       \n",
    "        daat = {'threshold': [],'N_Split':[], 'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "          'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "        data_vystup = pd.DataFrame(data=daat)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vystup.to_csv('vystup_Nsplits5,10_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.866921</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.00543478</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.94686</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.0531401</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.56567</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.637905</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.89726</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.10274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.925289</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.0243902</td>\n",
       "      <td>0.0384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.234299</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.767069</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.788121</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.0136986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.42162</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.399331</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.116883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.479265</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.840949</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>0.0105263</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>-0.040322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966019</td>\n",
       "      <td>0.0478469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.521282</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.309975</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.0793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.615741</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.239626</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.198198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.779028</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.0470588</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90099</td>\n",
       "      <td>-0.084096</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.0990099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.84507</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.61801</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.15493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.432789</td>\n",
       "      <td>0.54902</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.711465</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.540157</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.277977</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.150943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.441474</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.183099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  N_Split  Split  Accuracy Sensitiv.   Specif.       MCC  \\\n",
       "0         5.0      5.0    0.0  0.967593    0.8125  0.994565  0.866921   \n",
       "1         5.0      5.0    1.0  0.921296  0.333333   0.94686  0.227418   \n",
       "2         5.0      5.0    2.0  0.777778  0.892857  0.653846   0.56567   \n",
       "3         5.0      5.0    3.0  0.861111  0.980769      0.55  0.637905   \n",
       "4         5.0      5.0    4.0  0.736111   0.89726       0.4  0.348422   \n",
       "5         5.0     10.0    0.0  0.972222  0.961538   0.97561  0.925289   \n",
       "6         5.0     10.0    1.0  0.972222         0         1       NaN   \n",
       "7         5.0     10.0    2.0  1.000000         -         -         -   \n",
       "8         5.0     10.0    3.0  0.861111  0.428571  0.891089  0.234299   \n",
       "9         5.0     10.0    4.0  0.898148  0.958333  0.777778  0.767069   \n",
       "10        5.0     10.0    5.0  0.750000      0.82  0.689655  0.510448   \n",
       "11        5.0     10.0    6.0  0.907407  0.986301  0.742857  0.788121   \n",
       "12        5.0     10.0    7.0  0.870370  0.967033  0.352941   0.42162   \n",
       "13        5.0     10.0    8.0  0.768519  0.883117  0.483871  0.399331   \n",
       "14        5.0     10.0    9.0  0.824074  0.926829       0.5  0.479265   \n",
       "15        5.5      5.0    0.0  0.967593  0.807692  0.989474  0.840949   \n",
       "16        5.5      5.0    1.0  0.921296         0  0.952153 -0.040322   \n",
       "17        5.5      5.0    2.0  0.745370  0.863636  0.664062  0.521282   \n",
       "18        5.5      5.0    3.0  0.546296  0.920635  0.392157  0.309975   \n",
       "19        5.5      5.0    4.0  0.615741  0.801802  0.419048  0.239626   \n",
       "20        5.5     10.0    0.0  0.925926  0.826087  0.952941  0.779028   \n",
       "21        5.5     10.0    1.0  1.000000         -         -         -   \n",
       "22        5.5     10.0    2.0  1.000000         -         -         -   \n",
       "23        5.5     10.0    3.0  0.842593         0   0.90099 -0.084096   \n",
       "24        5.5     10.0    4.0  0.824074   0.84507  0.783784   0.61801   \n",
       "25        5.5     10.0    5.0  0.712963  0.777778  0.680556  0.432789   \n",
       "26        5.5     10.0    6.0  0.861111  0.890625  0.818182  0.711465   \n",
       "27        5.5     10.0    7.0  0.833333     0.925  0.571429  0.540157   \n",
       "28        5.5     10.0    8.0  0.620370  0.849057       0.4  0.277977   \n",
       "29        5.5     10.0    9.0  0.750000  0.816901  0.621622  0.441474   \n",
       "\n",
       "   Positive pred Negative pred False positive False negative  \n",
       "0       0.962963      0.968254     0.00543478         0.1875  \n",
       "1       0.214286      0.970297      0.0531401       0.666667  \n",
       "2       0.735294          0.85       0.346154       0.107143  \n",
       "3           0.85      0.916667           0.45      0.0192308  \n",
       "4       0.757225      0.651163            0.6        0.10274  \n",
       "5       0.925926      0.987654      0.0243902      0.0384615  \n",
       "6            NaN      0.972222              0              1  \n",
       "7              -             -              -              -  \n",
       "8       0.214286      0.957447       0.108911       0.571429  \n",
       "9       0.896104      0.903226       0.222222      0.0416667  \n",
       "10      0.694915      0.816327       0.310345           0.18  \n",
       "11      0.888889      0.962963       0.257143      0.0136986  \n",
       "12      0.888889      0.666667       0.647059       0.032967  \n",
       "13      0.809524         0.625       0.516129       0.116883  \n",
       "14      0.853933      0.684211            0.5      0.0731707  \n",
       "15      0.913043      0.974093      0.0105263       0.192308  \n",
       "16             0      0.966019      0.0478469              1  \n",
       "17      0.638655      0.876289       0.335938       0.136364  \n",
       "18      0.384106      0.923077       0.607843      0.0793651  \n",
       "19      0.593333      0.666667       0.580952       0.198198  \n",
       "20      0.826087      0.952941      0.0470588       0.173913  \n",
       "21             -             -              -              -  \n",
       "22             -             -              -              -  \n",
       "23             0      0.928571      0.0990099              1  \n",
       "24      0.882353         0.725       0.216216        0.15493  \n",
       "25       0.54902      0.859649       0.319444       0.222222  \n",
       "26      0.876923      0.837209       0.181818       0.109375  \n",
       "27      0.860465      0.727273       0.428571          0.075  \n",
       "28      0.576923      0.733333            0.6       0.150943  \n",
       "29      0.805556      0.638889       0.378378       0.183099  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vystup[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor score: 0.7140891324409928\n",
      "Table wherre you see pec50 , and pec50_new after regression model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pec50</th>\n",
       "      <th>pec50_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.362510</td>\n",
       "      <td>5.806693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.569777</td>\n",
       "      <td>5.851192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>7.247905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>7.151196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.100015</td>\n",
       "      <td>7.103867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>6.769551</td>\n",
       "      <td>6.182987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1076</td>\n",
       "      <td>7.094076</td>\n",
       "      <td>5.998179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>5.761954</td>\n",
       "      <td>4.344674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>4.170761</td>\n",
       "      <td>4.310835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>6.543634</td>\n",
       "      <td>5.986237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pec50  pec50_new\n",
       "0     6.362510   5.806693\n",
       "1     5.569777   5.851192\n",
       "2     8.500038   7.247905\n",
       "3     8.500038   7.151196\n",
       "4     7.100015   7.103867\n",
       "...        ...        ...\n",
       "1075  6.769551   6.182987\n",
       "1076  7.094076   5.998179\n",
       "1077  5.761954   4.344674\n",
       "1078  4.170761   4.310835\n",
       "1079  6.543634   5.986237\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Regresion model\n",
    "random_state = 20\n",
    "train_reg, test_reg = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train_reg, test_reg = train.copy(), test.copy()\n",
    "\n",
    "data_new_reg = [i for i in data_new['bin']]\n",
    "\n",
    "x_train_reg = [f for f in train_reg['bin']]\n",
    "x_test_reg = [f for f in test_reg['bin']]\n",
    "y_train_reg = [a for a in train_reg['pec50']]\n",
    "y_test_reg = [a for a in test_reg['pec50']]\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=101,max_depth=4, random_state=random_state)\n",
    "rfr.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "y_pred = rfr.predict(x_test_reg)\n",
    "sns.scatterplot(x=y_test_reg, y=y_pred)\n",
    "\n",
    "\n",
    "print(\"Regressor score:\", rfr.score(x_test_reg, y_test_reg))\n",
    "\n",
    "y_pred = rfr.predict(data_new_reg)\n",
    "data_new['pec50_new'] = y_pred\n",
    "\n",
    "df = pd.DataFrame({'pec50':[], 'pec50_new':[]})\n",
    "df['pec50'] = data_new['pec50']\n",
    "df['pec50_new'] = data_new['pec50_new']\n",
    "print(\"Table wherre you see pec50 , and pec50_new after regression model\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix for test set:\n",
      "[[259   3]\n",
      " [  1   7]]\n",
      "\n",
      "\n",
      "            predicted+  predicted-\n",
      "0  actual+           7           3\n",
      "1  actual-           1         259\n",
      "\n",
      "\n",
      "Accuracy: 0.9851851851851852\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       260\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.99       270\n",
      "   macro avg       0.93      0.85      0.89       270\n",
      "weighted avg       0.98      0.99      0.98       270\n",
      "\n",
      "Average absolute error: 0.01 degrees.\n",
      "Sensitivity: 0.875\n",
      "Specifity: 0.989\n",
      "MMC: 0.775\n",
      "Positive predictive 0.7\n",
      "Negative predictive 0.996\n",
      "False positive 0.011\n",
      "False negative 0.125\n",
      "False discovery 0.3\n",
      "Overall accuracy 0.985\n",
      "roc_auc_score for RandomForestClassification:  0.9985\n"
     ]
    }
   ],
   "source": [
    "#create classification model after reggresion model\n",
    "random_state = 20\n",
    "thre = 7\n",
    "\n",
    "#add new column\n",
    "data_new['category_new_reg'] = np.where(data_new['pec50_new']>=thre, 1, 0)\n",
    " \n",
    "\n",
    "#divided date for two sets: train and test\n",
    "train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train, test = train.copy(), test.copy()\n",
    "x_train = np.asarray([x for x in train['bin']])\n",
    "x_test = np.asarray([x for x in test['bin']]) \n",
    "y_train = np.asarray([y for y in train['category_new_reg']])\n",
    "y_test = np.asarray([y for y in test['category_new_reg']])\n",
    "\n",
    "#RandomForesrClassifier\n",
    "crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "crf.fit(x_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "crf_predict = crf.predict(x_test)\n",
    "\n",
    "#CLassification:\n",
    "   #accuracy, spe, sen, MCC,\n",
    "    #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "#confusion_matrix\n",
    "print(\"Confusion_matrix for test set:\")\n",
    "conf_matrix = confusion_matrix(crf.predict(x_test), y_test)\n",
    "print(conf_matrix)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(\"\\n\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "print(\"\\n\")\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, crf_predict))\n",
    "\n",
    "# Performance metrics\n",
    "errors = abs(crf_predict - y_test)\n",
    "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Sensitivity:\", round(TPR,3))\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(\"Specifity:\", round(TNR, 3))\n",
    "#MCC\n",
    "MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "print(\"MMC:\", round(MCC, 3))\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Positive predictive\", round(PPV,3))\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Negative predictive\", round(NPV,3))\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "print(\"False positive\", round(FPR,3))\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"False negative\", round(FNR,3))\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "print(\"False discovery\", round(FDR,3))\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Overall accuracy\", round(ACC,3))\n",
    "\n",
    "#put data for pandas data_out\n",
    "try:\n",
    "    dda = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "      'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "    ddff = pd.DataFrame(data=dda)\n",
    "\n",
    "    data_out_reg = data_out_reg.append(ddff, ignore_index = True)\n",
    "    data_out_reg.drop_duplicates(keep='first', inplace=True)\n",
    "except:\n",
    "    ddaa = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "      'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "    data_out_reg = pd.DataFrame(data=ddaa)\n",
    "\n",
    "\n",
    "\n",
    "y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        5.5  0.966667   0.992754  0.939394  0.934485       0.944828   \n",
       "1        5.0  0.970370   0.986111  0.952381  0.940776       0.959459   \n",
       "2        6.0  0.870370   0.939759  0.839572  0.734028       0.722222   \n",
       "3        6.5  0.955556   1.000000  0.953125  0.716395       0.538462   \n",
       "4        7.0  0.985185   0.875000  0.988550  0.775347       0.700000   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       0.992000        0.060606        0.007246  \n",
       "1       0.983607        0.047619        0.013889  \n",
       "2       0.969136        0.160428        0.060241  \n",
       "3       1.000000        0.046875        0.000000  \n",
       "4       0.996154        0.011450        0.125000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_reg.to_csv('data_out_reg_diferentthreshold_clasification_modelafter_reg.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_diferent_threshold_clasification_model.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for classifikation model(step 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.202335</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        7.0  0.881481   1.000000  0.878327  0.397050   \n",
       "1           1        5.0  0.918519   0.923611  0.912698  0.836310   \n",
       "2           2        5.5  0.870370   0.852713  0.886525  0.740154   \n",
       "3           3        6.0  0.800000   0.880000  0.781818  0.542414   \n",
       "4           4        6.5  0.803704   0.923077  0.797665  0.362823   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.179487       1.000000        0.121673        0.000000  \n",
       "1       0.923611       0.912698        0.087302        0.076389  \n",
       "2       0.873016       0.868056        0.113475        0.147287  \n",
       "3       0.478261       0.966292        0.218182        0.120000  \n",
       "4       0.187500       0.995146        0.202335        0.076923  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data for classifikation model(step 1)\")\n",
    "data_clas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after croos validation for classification model (step1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9945652173913043</td>\n",
       "      <td>0.8669214468630108</td>\n",
       "      <td>0.9629629629629629</td>\n",
       "      <td>0.9682539682539683</td>\n",
       "      <td>0.005434782608695652</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>0.9468599033816425</td>\n",
       "      <td>0.22741775761782826</td>\n",
       "      <td>0.21428571428571427</td>\n",
       "      <td>0.9702970297029703</td>\n",
       "      <td>0.05314009661835749</td>\n",
       "      <td>0.6666666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.8928571428571429</td>\n",
       "      <td>0.6538461538461539</td>\n",
       "      <td>0.5656697125166719</td>\n",
       "      <td>0.7352941176470589</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.34615384615384615</td>\n",
       "      <td>0.10714285714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.9807692307692307</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.6379052256590134</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.9166666666666666</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.019230769230769232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.8972602739726028</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3484215771445816</td>\n",
       "      <td>0.7572254335260116</td>\n",
       "      <td>0.6511627906976745</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.10273972602739725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9444444444444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05555555555555555</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8981481481481481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10185185185185185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7755102040816326</td>\n",
       "      <td>0.4328313827668359</td>\n",
       "      <td>0.2903225806451613</td>\n",
       "      <td>0.987012987012987</td>\n",
       "      <td>0.22448979591836735</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.7777777777777778</td>\n",
       "      <td>0.8383838383838383</td>\n",
       "      <td>0.4159681814955806</td>\n",
       "      <td>0.30434782608695654</td>\n",
       "      <td>0.9764705882352941</td>\n",
       "      <td>0.16161616161616163</td>\n",
       "      <td>0.2222222222222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8055555555555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19444444444444445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  threshold  N_Split  Split  Accuracy           Sensitiv.  \\\n",
       "0            0        5.0      5.0    0.0  0.967593              0.8125   \n",
       "1            1        5.0      5.0    1.0  0.921296  0.3333333333333333   \n",
       "2            2        5.0      5.0    2.0  0.777778  0.8928571428571429   \n",
       "3            3        5.0      5.0    3.0  0.861111  0.9807692307692307   \n",
       "4            4        5.0      5.0    4.0  0.736111  0.8972602739726028   \n",
       "..         ...        ...      ...    ...       ...                 ...   \n",
       "70          70        7.0     10.0    5.0  0.944444                 NaN   \n",
       "71          71        7.0     10.0    6.0  0.898148                 NaN   \n",
       "72          72        7.0     10.0    7.0  0.787037                 0.9   \n",
       "73          73        7.0     10.0    8.0  0.833333  0.7777777777777778   \n",
       "74          74        7.0     10.0    9.0  0.805556                 NaN   \n",
       "\n",
       "               Specif.                  MCC        Positive pred  \\\n",
       "0   0.9945652173913043   0.8669214468630108   0.9629629629629629   \n",
       "1   0.9468599033816425  0.22741775761782826  0.21428571428571427   \n",
       "2   0.6538461538461539   0.5656697125166719   0.7352941176470589   \n",
       "3                 0.55   0.6379052256590134                 0.85   \n",
       "4                  0.4   0.3484215771445816   0.7572254335260116   \n",
       "..                 ...                  ...                  ...   \n",
       "70  0.9444444444444444                  NaN                  0.0   \n",
       "71  0.8981481481481481                  NaN                  0.0   \n",
       "72  0.7755102040816326   0.4328313827668359   0.2903225806451613   \n",
       "73  0.8383838383838383   0.4159681814955806  0.30434782608695654   \n",
       "74  0.8055555555555556                  NaN                  0.0   \n",
       "\n",
       "         Negative pred        False positive        False negative  \n",
       "0   0.9682539682539683  0.005434782608695652                0.1875  \n",
       "1   0.9702970297029703   0.05314009661835749    0.6666666666666666  \n",
       "2                 0.85   0.34615384615384615   0.10714285714285714  \n",
       "3   0.9166666666666666                  0.45  0.019230769230769232  \n",
       "4   0.6511627906976745                   0.6   0.10273972602739725  \n",
       "..                 ...                   ...                   ...  \n",
       "70                 1.0   0.05555555555555555                   NaN  \n",
       "71                 1.0   0.10185185185185185                   NaN  \n",
       "72   0.987012987012987   0.22448979591836735                   0.1  \n",
       "73  0.9764705882352941   0.16161616161616163    0.2222222222222222  \n",
       "74                 1.0   0.19444444444444445                   NaN  \n",
       "\n",
       "[75 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_cros = pd.read_csv('/home/valeriia/bakalarka/bakalarka/vystup_Nsplits5,10_clasification_model.csv')\n",
    "print(\"Data after croos validation for classification model (step1)\")\n",
    "data_clas_cros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data classifikation(which i built after regresion model)(step 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        5.5  0.966667   0.992754  0.939394  0.934485   \n",
       "1           1        5.0  0.970370   0.986111  0.952381  0.940776   \n",
       "2           2        6.0  0.870370   0.939759  0.839572  0.734028   \n",
       "3           3        6.5  0.955556   1.000000  0.953125  0.716395   \n",
       "4           4        7.0  0.985185   0.875000  0.988550  0.775347   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.944828       0.992000        0.060606        0.007246  \n",
       "1       0.959459       0.983607        0.047619        0.013889  \n",
       "2       0.722222       0.969136        0.160428        0.060241  \n",
       "3       0.538462       1.000000        0.046875        0.000000  \n",
       "4       0.700000       0.996154        0.011450        0.125000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_reg = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_reg_diferentthreshold_clasification_modelafter_reg.csv')\n",
    "print(\"Data classifikation(which i built after regresion model)(step 2)\")\n",
    "data_clas_reg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
