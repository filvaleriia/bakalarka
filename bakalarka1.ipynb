{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [20:17:00] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/valeriia/bakalarka/bakalarka/LXRb_ch25_curated_DW_2.csv')\n",
    "# copy raw data\n",
    "data_new = data.copy()\n",
    "data_new[\"Molecule\"] = [Chem.MolFromSmiles(mol) for mol in data[\"smiles\"]]\n",
    "\n",
    "#colmun['Molecule'] invert to binary systems\n",
    "data_new['bin'] = [np.array(AllChem.GetMorganFingerprintAsBitVect(i,2, nBits=1024)) for i in data_new['Molecule']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>potency</th>\n",
       "      <th>pec50</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C</td>\n",
       "      <td>CHEMBL1023</td>\n",
       "      <td>434.000</td>\n",
       "      <td>6.362510</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...</td>\n",
       "      <td>CHEMBL1089232</td>\n",
       "      <td>2805.000</td>\n",
       "      <td>5.569777</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...</td>\n",
       "      <td>CHEMBL1091034</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...</td>\n",
       "      <td>CHEMBL1091976</td>\n",
       "      <td>3.162</td>\n",
       "      <td>8.500038</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...</td>\n",
       "      <td>CHEMBL1092952</td>\n",
       "      <td>79.430</td>\n",
       "      <td>7.100015</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles      chembl_id   potency  \\\n",
       "0   Cc1cc2c(cc1C(=C)c3ccc(cc3)C(=O)O)C(C)(C)CCC2(C)C     CHEMBL1023   434.000   \n",
       "1  CCc1nc2c(cccc2nc1c3ccc(cc3)c4cccc(c4)S(=O)(=O)...  CHEMBL1089232  2805.000   \n",
       "2  CS(=O)(=O)c1cccc(c1)c2ccc(CN(Cc3ccc(F)cc3Cl)S(...  CHEMBL1091034     3.162   \n",
       "3  Cc1ccccc1S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O)...  CHEMBL1091976     3.162   \n",
       "4  Cn1cnc(c1)S(=O)(=O)N(Cc2ccc(cc2)c3cccc(c3)S(=O...  CHEMBL1092952    79.430   \n",
       "\n",
       "      pec50  category  \n",
       "0  6.362510    active  \n",
       "1  5.569777  inactive  \n",
       "2  8.500038    active  \n",
       "3  8.500038    active  \n",
       "4  7.100015    active  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9023956711255896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.pec50.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix for test set:\n",
      "[[231  32]\n",
      " [  0   7]]\n",
      "\n",
      "\n",
      "            predicted+  predicted-\n",
      "0  actual+           7          32\n",
      "1  actual-           0         231\n",
      "\n",
      "\n",
      "Accuracy: 0.8814814814814815\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       231\n",
      "           1       1.00      0.18      0.30        39\n",
      "\n",
      "    accuracy                           0.88       270\n",
      "   macro avg       0.94      0.59      0.62       270\n",
      "weighted avg       0.90      0.88      0.84       270\n",
      "\n",
      "roc_auc_score for RandomForestClassification:  0.9154\n"
     ]
    }
   ],
   "source": [
    "##### classifikation model change thre and than i compare date for diferent thre\n",
    "#this model predict active/inactive compounds\n",
    "#case1\n",
    "random_state = 20\n",
    "thre = 7\n",
    "\n",
    "#add new columns, number of columns\n",
    "data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "#divided date for two sets: train and test\n",
    "train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train, test = train.copy(), test.copy()\n",
    "x_train = np.asarray([x for x in train['bin']])\n",
    "x_test = np.asarray([x for x in test['bin']]) \n",
    "y_train = np.asarray([y for y in train['category_new']])\n",
    "y_test = np.asarray([y for y in test['category_new']])\n",
    "\n",
    "#RandomForesrClassifier\n",
    "crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "crf.fit(x_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "crf_predict = crf.predict(x_test)\n",
    "\n",
    "#CLassification:\n",
    "   #accuracy, spe, sen, MCC,\n",
    "    #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "#confusion_matrix\n",
    "print(\"Confusion_matrix for test set:\")\n",
    "conf_matrix = confusion_matrix(crf.predict(x_test), y_test)\n",
    "print(conf_matrix)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(\"\\n\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "print(\"\\n\")\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, crf_predict))\n",
    "\n",
    "# Performance metrics\n",
    "errors = abs(crf_predict - y_test)\n",
    "#print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "#MCC\n",
    "MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "#put data for pandas data_out\n",
    "try:\n",
    "    da = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "      'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "    dff = pd.DataFrame(data=da)\n",
    "\n",
    "    data_out = data_out.append(dff, ignore_index = True)\n",
    "    data_out.drop_duplicates(keep='first', inplace=True)\n",
    "except:\n",
    "    da = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "      'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "    data_out = pd.DataFrame(data=da)\n",
    "\n",
    "\n",
    "\n",
    "y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.202335</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        7.0  0.881481   1.000000  0.878327  0.397050       0.179487   \n",
       "1        5.0  0.918519   0.923611  0.912698  0.836310       0.923611   \n",
       "2        5.5  0.870370   0.852713  0.886525  0.740154       0.873016   \n",
       "3        6.0  0.800000   0.880000  0.781818  0.542414       0.478261   \n",
       "4        6.5  0.803704   0.923077  0.797665  0.362823       0.187500   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       1.000000        0.121673        0.000000  \n",
       "1       0.912698        0.087302        0.076389  \n",
       "2       0.868056        0.113475        0.147287  \n",
       "3       0.966292        0.218182        0.120000  \n",
       "4       0.995146        0.202335        0.076923  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_csv('data_out_diferent_threshold_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation_score [0.88425926 0.88425926 0.89814815 0.87962963 0.875     ]\n",
      "Cross validation:\n",
      "Number of split: 0\n",
      "Accuracy: 0.9537037037037037\n",
      "[[206  10]\n",
      " [  0   0]]\n",
      "Number of split: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9814814814814815\n",
      "[[212   4]\n",
      " [  0   0]]\n",
      "Number of split: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8842592592592593\n",
      "[[191  25]\n",
      " [  0   0]]\n",
      "Number of split: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8379629629629629\n",
      "[[172  33]\n",
      " [  2   9]]\n",
      "Number of split: 4\n",
      "Accuracy: 0.8194444444444444\n",
      "[[172  39]\n",
      " [  0   5]]\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "n_splits = 5\n",
    "thre = 7\n",
    "random_state = 20\n",
    "\n",
    "data_new['number'] = data_new['chembl_id'].rank(method='min')\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_new['number']= lab_enc.fit_transform(data_new['number'])\n",
    "data_new['category_new'] = np.where(data_new['pec50']>=thre, 1, 0)\n",
    "\n",
    "cros_x = np.asarray([x for x in data_new['bin']])\n",
    "cros_y = np.asarray([y for y in data_new['category_new']])\n",
    "scores = cross_val_score(crf, cros_x, cros_y, cv=n_splits)\n",
    "print(\"Cross_validation_score\", scores)\n",
    "#Cross Validation\n",
    "print(\"Cross validation:\")\n",
    "kf = KFold(n_splits = n_splits)\n",
    "a = -1   \n",
    "        \n",
    "for trains, tests in kf.split(cros_x, cros_y):\n",
    "    a = a+1\n",
    "    print('Number of split:', a)\n",
    "    rfc = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    rfc.fit(cros_x[trains],cros_y[trains])\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests])))\n",
    "    rfc_predict = rfc.predict(cros_x[tests])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(rfc.predict(cros_x[tests]),\n",
    "                                   cros_y[tests])\n",
    "    \n",
    "    print(conf_matrix)\n",
    "    \n",
    "    accur = metrics.accuracy_score(cros_y[tests], rfc.predict(cros_x[tests]))\n",
    "    if(accur == 1):\n",
    "        ACC = 1\n",
    "        TPR = 1\n",
    "        TNR = 1\n",
    "        MCC = 1\n",
    "        PPV = 1\n",
    "        NPV = 1\n",
    "        FPR = 1\n",
    "        FNR = 1\n",
    "        FDR = 1\n",
    "    else:\n",
    "        TN, FP, FN, TP = conf_matrix.ravel()\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = TP/(TP+FN)\n",
    "        # Specificity or true negative rate\n",
    "        TNR = TN/(TN+FP)\n",
    "        #MCC\n",
    "        MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "        # Precision or positive predictive value\n",
    "        PPV = TP/(TP+FP)\n",
    "        # Negative predictive value\n",
    "        NPV = TN/(TN+FN)\n",
    "        # Fall out or false positive rate\n",
    "        FPR = FP/(FP+TN)\n",
    "        # False negative rate\n",
    "        FNR = FN/(TP+FN)\n",
    "        # False discovery rate\n",
    "        FDR = FP/(TP+FP)\n",
    "        # Overall accuracy\n",
    "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    \n",
    "    #put data for pandas data_out   \n",
    "    try:\n",
    "        dat = {'threshold': [thre],'N_Split':[n_splits],'Split':[a],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "            'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "        daf = pd.DataFrame(data=dat)\n",
    "        \n",
    "        data_vystup = data_vystup.append(daf, ignore_index = True)\n",
    "        data_vystup.drop_duplicates(keep='first', inplace=True) \n",
    "    except:\n",
    "       \n",
    "        dat = {'threshold': [],'N_Split':[], 'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "          'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "        data_vystup = pd.DataFrame(data=dat)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vystup.to_csv('vystup_Nsplits5,10_clasification_model.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.223424</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.553922</td>\n",
       "      <td>0.139617</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.446078</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.123753</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.866921</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946860</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.565670</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.637905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.102740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.840949</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>-0.040322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966019</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.521282</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.309975</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.079365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.615741</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.239626</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.198198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.705430</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.994872</td>\n",
       "      <td>0.044335</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.269443</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653659</td>\n",
       "      <td>0.296118</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.839024</td>\n",
       "      <td>0.365070</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.160976</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.304356</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  N_Split  Split  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0         6.0      5.0    1.0  0.953704        NaN  0.953704       NaN   \n",
       "1         6.0      5.0    2.0  0.601852   1.000000  0.586538  0.223424   \n",
       "2         6.0      5.0    3.0  0.564815   0.750000  0.553922  0.139617   \n",
       "3         6.0      5.0    4.0  0.546296   0.625000  0.523810  0.123753   \n",
       "4         5.0      5.0    0.0  0.967593   0.812500  0.994565  0.866921   \n",
       "5         5.0      5.0    1.0  0.921296   0.333333  0.946860  0.227418   \n",
       "6         5.0      5.0    2.0  0.777778   0.892857  0.653846  0.565670   \n",
       "7         5.0      5.0    3.0  0.861111   0.980769  0.550000  0.637905   \n",
       "8         5.0      5.0    4.0  0.736111   0.897260  0.400000  0.348422   \n",
       "9         5.5      5.0    0.0  0.967593   0.807692  0.989474  0.840949   \n",
       "10        5.5      5.0    1.0  0.921296   0.000000  0.952153 -0.040322   \n",
       "11        5.5      5.0    2.0  0.745370   0.863636  0.664062  0.521282   \n",
       "12        5.5      5.0    3.0  0.546296   0.920635  0.392157  0.309975   \n",
       "13        5.5      5.0    4.0  0.615741   0.801802  0.419048  0.239626   \n",
       "14        6.0      5.0    0.0  0.953704   0.923077  0.955665  0.705430   \n",
       "15        6.5      5.0    0.0  0.930556        NaN  0.930556       NaN   \n",
       "16        6.5      5.0    1.0  0.962963        NaN  0.962963       NaN   \n",
       "17        6.5      5.0    2.0  0.754630        NaN  0.754630       NaN   \n",
       "18        6.5      5.0    3.0  0.745370   1.000000  0.738095  0.269443   \n",
       "19        6.5      5.0    4.0  0.671296   1.000000  0.653659  0.296118   \n",
       "20        7.0      5.0    0.0  0.953704        NaN  0.953704       NaN   \n",
       "21        7.0      5.0    1.0  0.981481        NaN  0.981481       NaN   \n",
       "22        7.0      5.0    2.0  0.884259        NaN  0.884259       NaN   \n",
       "23        7.0      5.0    3.0  0.837963   0.818182  0.839024  0.365070   \n",
       "24        7.0      5.0    4.0  0.819444   1.000000  0.815166  0.304356   \n",
       "\n",
       "    Positive pred  Negative pred  False positive  False negative  \n",
       "0        0.000000       1.000000        0.046296             NaN  \n",
       "1        0.085106       1.000000        0.413462        0.000000  \n",
       "2        0.090000       0.974138        0.446078        0.250000  \n",
       "3        0.272727       0.830189        0.476190        0.375000  \n",
       "4        0.962963       0.968254        0.005435        0.187500  \n",
       "5        0.214286       0.970297        0.053140        0.666667  \n",
       "6        0.735294       0.850000        0.346154        0.107143  \n",
       "7        0.850000       0.916667        0.450000        0.019231  \n",
       "8        0.757225       0.651163        0.600000        0.102740  \n",
       "9        0.913043       0.974093        0.010526        0.192308  \n",
       "10       0.000000       0.966019        0.047847        1.000000  \n",
       "11       0.638655       0.876289        0.335938        0.136364  \n",
       "12       0.384106       0.923077        0.607843        0.079365  \n",
       "13       0.593333       0.666667        0.580952        0.198198  \n",
       "14       0.571429       0.994872        0.044335        0.076923  \n",
       "15       0.000000       1.000000        0.069444             NaN  \n",
       "16       0.000000       1.000000        0.037037             NaN  \n",
       "17       0.000000       1.000000        0.245370             NaN  \n",
       "18       0.098361       1.000000        0.261905        0.000000  \n",
       "19       0.134146       1.000000        0.346341        0.000000  \n",
       "20       0.000000       1.000000        0.046296             NaN  \n",
       "21       0.000000       1.000000        0.018519             NaN  \n",
       "22       0.000000       1.000000        0.115741             NaN  \n",
       "23       0.214286       0.988506        0.160976        0.181818  \n",
       "24       0.113636       1.000000        0.184834        0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vystup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table when you see old pec50 and new pec50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pec50</th>\n",
       "      <th>pec50_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.362510</td>\n",
       "      <td>5.714543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.569777</td>\n",
       "      <td>6.517781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.500038</td>\n",
       "      <td>6.775484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.500038</td>\n",
       "      <td>7.604964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.100015</td>\n",
       "      <td>7.249329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>6.769551</td>\n",
       "      <td>6.855233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>7.094076</td>\n",
       "      <td>5.840604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>5.761954</td>\n",
       "      <td>4.291746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>4.170761</td>\n",
       "      <td>4.273384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>6.543634</td>\n",
       "      <td>5.885988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pec50  pec50_new\n",
       "0     6.362510   5.714543\n",
       "1     5.569777   6.517781\n",
       "2     8.500038   6.775484\n",
       "3     8.500038   7.604964\n",
       "4     7.100015   7.249329\n",
       "...        ...        ...\n",
       "1075  6.769551   6.855233\n",
       "1076  7.094076   5.840604\n",
       "1077  5.761954   4.291746\n",
       "1078  4.170761   4.273384\n",
       "1079  6.543634   5.885988\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor score: 0.21633052336270453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Regresion model\n",
    "#case2.1\n",
    "\n",
    "random_state = 20\n",
    "train_reg, test_reg = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train_reg, test_reg = train.copy(), test.copy()\n",
    "\n",
    "data_new_reg = [i for i in data_new['bin']]\n",
    "\n",
    "\n",
    "x_train_reg = [f for f in train_reg['bin']]\n",
    "x_test_reg = [f for f in test_reg['bin']]\n",
    "y_train_reg = [a for a in train_reg['pec50']]\n",
    "y_test_reg = [a for a in test_reg['pec50']]\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=101,max_depth=4, random_state=random_state)\n",
    "rfr.fit(x_train_reg, y_train_reg)\n",
    "\n",
    "y_pred = rfr.predict(x_test_reg)\n",
    "sns.scatterplot(x=y_test_reg, y=y_pred)\n",
    "\n",
    "y_pred = rfr.predict(data_new_reg)\n",
    "data_new['pec50_new'] = y_pred\n",
    "\n",
    "df = pd.DataFrame({'pec50':[], 'pec50_new':[]})\n",
    "df['pec50'] = data_new['pec50']\n",
    "df['pec50_new'] = data_new['pec50_new']\n",
    "print(\"Table when you see old pec50 and new pec50\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "print(\"Regressor score:\", rfr.score(x_test_reg, y_test_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix for test set:\n",
      "[[259   3]\n",
      " [  1   7]]\n",
      "\n",
      "\n",
      "            predicted+  predicted-\n",
      "0  actual+           7           3\n",
      "1  actual-           1         259\n",
      "\n",
      "\n",
      "Accuracy: 0.9851851851851852\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       260\n",
      "           1       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.99       270\n",
      "   macro avg       0.93      0.85      0.89       270\n",
      "weighted avg       0.98      0.99      0.98       270\n",
      "\n",
      "roc_auc_score for RandomForestClassification:  0.9985\n"
     ]
    }
   ],
   "source": [
    "#create classification model after reggresion model\n",
    "#case2.2s\n",
    "random_state = 20\n",
    "thre = 7\n",
    "\n",
    "#add new column\n",
    "data_new['category_new_reg'] = np.where(data_new['pec50_new']>=thre, 1, 0)\n",
    " \n",
    "\n",
    "#divided date for two sets: train and test\n",
    "train, test = train_test_split(data_new, test_size = 0.25, random_state = random_state)\n",
    "train, test = train.copy(), test.copy()\n",
    "x_train = np.asarray([x for x in train['bin']])\n",
    "x_test = np.asarray([x for x in test['bin']]) \n",
    "y_train = np.asarray([y for y in train['category_new_reg']])\n",
    "y_test = np.asarray([y for y in test['category_new_reg']])\n",
    "\n",
    "#RandomForesrClassifier\n",
    "crf = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "crf.fit(x_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "crf_predict = crf.predict(x_test)\n",
    "\n",
    "#CLassification:\n",
    "   #accuracy, spe, sen, MCC,\n",
    "    #confusion matrices (true positive, true negative, false positive, false negative (TP, TN, FP, FN))\n",
    "    \n",
    "#confusion_matrix\n",
    "print(\"Confusion_matrix for test set:\")\n",
    "conf_matrix = confusion_matrix(crf.predict(x_test), y_test)\n",
    "print(conf_matrix)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "d = {' ': ['actual+', 'actual-'], 'predicted+':[TP, FN], 'predicted-':[FP, TN]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(\"\\n\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, crf.predict(x_test)))\n",
    "print(\"\\n\")\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, crf_predict))\n",
    "\n",
    "# Performance metrics\n",
    "errors = abs(crf_predict - y_test)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "#MCC\n",
    "MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "#put data for pandas data_out\n",
    "try:\n",
    "    dda = {'threshold': [thre],'Accuracy':[ACC], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC],\n",
    "      'Positive pred':[PPV], 'Negative pred':[NPV], 'False positive':[FPR], 'False negative':[FNR]}\n",
    "    ddff = pd.DataFrame(data=dda)\n",
    "\n",
    "    data_out_reg = data_out_reg.append(ddff, ignore_index = True)\n",
    "    data_out_reg.drop_duplicates(keep='first', inplace=True)\n",
    "except:\n",
    "    dda = {'threshold': [],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[],\n",
    "      'Positive pred':[], 'Negative pred':[], 'False positive':[], 'False negative':[]}\n",
    "    data_out_reg = pd.DataFrame(data=dda)\n",
    "\n",
    "\n",
    "\n",
    "y_score1 = crf.predict_proba(x_test)[:,1]\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "print('roc_auc_score for RandomForestClassification: ', round(roc_auc_score(y_test, y_score1),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  Accuracy  Sensitiv.   Specif.       MCC  Positive pred  \\\n",
       "0        5.5  0.966667   0.992754  0.939394  0.934485       0.944828   \n",
       "1        5.0  0.970370   0.986111  0.952381  0.940776       0.959459   \n",
       "2        6.0  0.870370   0.939759  0.839572  0.734028       0.722222   \n",
       "3        6.5  0.955556   1.000000  0.953125  0.716395       0.538462   \n",
       "4        7.0  0.985185   0.875000  0.988550  0.775347       0.700000   \n",
       "\n",
       "   Negative pred  False positive  False negative  \n",
       "0       0.992000        0.060606        0.007246  \n",
       "1       0.983607        0.047619        0.013889  \n",
       "2       0.969136        0.160428        0.060241  \n",
       "3       1.000000        0.046875        0.000000  \n",
       "4       0.996154        0.011450        0.125000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_reg.to_csv('data_out_reg_diferentthreshold_clasification_modelafter_reg.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for classifikation model(step 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.202335</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        7.0  0.881481   1.000000  0.878327  0.397050   \n",
       "1           1        5.0  0.918519   0.923611  0.912698  0.836310   \n",
       "2           2        5.5  0.870370   0.852713  0.886525  0.740154   \n",
       "3           3        6.0  0.800000   0.880000  0.781818  0.542414   \n",
       "4           4        6.5  0.803704   0.923077  0.797665  0.362823   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.179487       1.000000        0.121673        0.000000  \n",
       "1       0.923611       0.912698        0.087302        0.076389  \n",
       "2       0.873016       0.868056        0.113475        0.147287  \n",
       "3       0.478261       0.966292        0.218182        0.120000  \n",
       "4       0.187500       0.995146        0.202335        0.076923  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_diferent_threshold_clasification_model.csv')\n",
    "print(\"Data for classifikation model(step 1)\")\n",
    "data_clas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after croos validation for classification model (step1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>N_Split</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.866921</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946860</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.565670</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.637905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.102740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.432831</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.415968</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  threshold  N_Split  Split  Accuracy  Sensitiv.   Specif.  \\\n",
       "0            0        5.0      5.0    0.0  0.967593   0.812500  0.994565   \n",
       "1            1        5.0      5.0    1.0  0.921296   0.333333  0.946860   \n",
       "2            2        5.0      5.0    2.0  0.777778   0.892857  0.653846   \n",
       "3            3        5.0      5.0    3.0  0.861111   0.980769  0.550000   \n",
       "4            4        5.0      5.0    4.0  0.736111   0.897260  0.400000   \n",
       "..         ...        ...      ...    ...       ...        ...       ...   \n",
       "70          70        7.0     10.0    5.0  0.944444        NaN  0.944444   \n",
       "71          71        7.0     10.0    6.0  0.898148        NaN  0.898148   \n",
       "72          72        7.0     10.0    7.0  0.787037   0.900000  0.775510   \n",
       "73          73        7.0     10.0    8.0  0.833333   0.777778  0.838384   \n",
       "74          74        7.0     10.0    9.0  0.805556        NaN  0.805556   \n",
       "\n",
       "         MCC  Positive pred  Negative pred  False positive  False negative  \n",
       "0   0.866921       0.962963       0.968254        0.005435        0.187500  \n",
       "1   0.227418       0.214286       0.970297        0.053140        0.666667  \n",
       "2   0.565670       0.735294       0.850000        0.346154        0.107143  \n",
       "3   0.637905       0.850000       0.916667        0.450000        0.019231  \n",
       "4   0.348422       0.757225       0.651163        0.600000        0.102740  \n",
       "..       ...            ...            ...             ...             ...  \n",
       "70       NaN       0.000000       1.000000        0.055556             NaN  \n",
       "71       NaN       0.000000       1.000000        0.101852             NaN  \n",
       "72  0.432831       0.290323       0.987013        0.224490        0.100000  \n",
       "73  0.415968       0.304348       0.976471        0.161616        0.222222  \n",
       "74       NaN       0.000000       1.000000        0.194444             NaN  \n",
       "\n",
       "[75 rows x 12 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_cros = pd.read_csv('/home/valeriia/bakalarka/bakalarka/vystup_Nsplits5,10_clasification_model.csv')\n",
    "print(\"Data after croos validation for classification model (step1)\")\n",
    "data_clas_cros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data classifikation(which i built after regresion model)(step 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Positive pred</th>\n",
       "      <th>Negative pred</th>\n",
       "      <th>False positive</th>\n",
       "      <th>False negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.934485</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.940776</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.734028</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.775347</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  threshold  Accuracy  Sensitiv.   Specif.       MCC  \\\n",
       "0           0        5.5  0.966667   0.992754  0.939394  0.934485   \n",
       "1           1        5.0  0.970370   0.986111  0.952381  0.940776   \n",
       "2           2        6.0  0.870370   0.939759  0.839572  0.734028   \n",
       "3           3        6.5  0.955556   1.000000  0.953125  0.716395   \n",
       "4           4        7.0  0.985185   0.875000  0.988550  0.775347   \n",
       "\n",
       "   Positive pred  Negative pred  False positive  False negative  \n",
       "0       0.944828       0.992000        0.060606        0.007246  \n",
       "1       0.959459       0.983607        0.047619        0.013889  \n",
       "2       0.722222       0.969136        0.160428        0.060241  \n",
       "3       0.538462       1.000000        0.046875        0.000000  \n",
       "4       0.700000       0.996154        0.011450        0.125000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas_reg = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_reg_diferentthreshold_clasification_modelafter_reg.csv')\n",
    "print(\"Data classifikation(which i built after regresion model)(step 2)\")\n",
    "data_clas_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW KOD:\n",
    "#end table\n",
    "\n",
    "data = pd.read_csv('/home/valeriia/bakalarka/bakalarka/LXRb_ch25_curated_DW_2.csv')\n",
    "# copy raw data\n",
    "data_new_2 = data.copy()\n",
    "data_new_2[\"Molecule\"] = [Chem.MolFromSmiles(mol) for mol in data[\"smiles\"]]\n",
    "\n",
    "#colmun['Molecule'] invert to binary systems\n",
    "data_new_2['bin'] = [np.array(AllChem.GetMorganFingerprintAsBitVect(i,2, nBits=1024)) for i in data_new_2['Molecule']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regr 0.6540539722230213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regr 0.40994541417868363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/valeriia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regr 0.7541837378282931\n",
      "Regr 0.7794605727865181\n",
      "Regr 0.9650674254426206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.866921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946860</td>\n",
       "      <td>0.227418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.565670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.637905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.348422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.840949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>-0.040322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.521282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.309975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.615741</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.239626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.705430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.223424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.553922</td>\n",
       "      <td>0.139617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.123753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.269443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653659</td>\n",
       "      <td>0.296118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.839024</td>\n",
       "      <td>0.365070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.304356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.678580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.652507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.833464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.876038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.769732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.713810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.758583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.882227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.778126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.802222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.412336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.670728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.489644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.551677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.705460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.729704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case  threshold  Split  Accuracy  Sensitiv.   Specif.       MCC\n",
       "0    1.0        5.0    0.0  0.967593   0.812500  0.994565  0.866921\n",
       "1    1.0        5.0    1.0  0.921296   0.333333  0.946860  0.227418\n",
       "2    1.0        5.0    2.0  0.777778   0.892857  0.653846  0.565670\n",
       "3    1.0        5.0    3.0  0.861111   0.980769  0.550000  0.637905\n",
       "4    1.0        5.0    4.0  0.736111   0.897260  0.400000  0.348422\n",
       "5    1.0        5.5    0.0  0.967593   0.807692  0.989474  0.840949\n",
       "6    1.0        5.5    1.0  0.921296   0.000000  0.952153 -0.040322\n",
       "7    1.0        5.5    2.0  0.745370   0.863636  0.664062  0.521282\n",
       "8    1.0        5.5    3.0  0.546296   0.920635  0.392157  0.309975\n",
       "9    1.0        5.5    4.0  0.615741   0.801802  0.419048  0.239626\n",
       "10   1.0        6.0    0.0  0.953704   0.923077  0.955665  0.705430\n",
       "11   1.0        6.0    1.0  0.953704        NaN  0.953704       NaN\n",
       "12   1.0        6.0    2.0  0.601852   1.000000  0.586538  0.223424\n",
       "13   1.0        6.0    3.0  0.564815   0.750000  0.553922  0.139617\n",
       "14   1.0        6.0    4.0  0.546296   0.625000  0.523810  0.123753\n",
       "15   1.0        6.5    0.0  0.930556        NaN  0.930556       NaN\n",
       "16   1.0        6.5    1.0  0.962963        NaN  0.962963       NaN\n",
       "17   1.0        6.5    2.0  0.754630        NaN  0.754630       NaN\n",
       "18   1.0        6.5    3.0  0.745370   1.000000  0.738095  0.269443\n",
       "19   1.0        6.5    4.0  0.671296   1.000000  0.653659  0.296118\n",
       "20   1.0        7.0    0.0  0.953704        NaN  0.953704       NaN\n",
       "21   1.0        7.0    1.0  0.981481        NaN  0.981481       NaN\n",
       "22   1.0        7.0    2.0  0.884259        NaN  0.884259       NaN\n",
       "23   1.0        7.0    3.0  0.837963   0.818182  0.839024  0.365070\n",
       "24   1.0        7.0    4.0  0.819444   1.000000  0.815166  0.304356\n",
       "25   2.2        5.0    0.0  0.916667   0.750000  0.945652  0.678580\n",
       "26   2.2        5.0    1.0  0.949074   0.909091  0.951220  0.652507\n",
       "27   2.2        5.0    2.0  0.916667   0.975410  0.840426  0.833464\n",
       "28   2.2        5.0    3.0  0.953704   1.000000  0.814815  0.876038\n",
       "29   2.2        5.0    4.0  0.898148   1.000000  0.681159  0.769732\n",
       "30   2.2        5.5    0.0  0.930556   0.741935  0.962162  0.713810\n",
       "31   2.2        5.5    1.0  0.976852   0.888889  0.980676  0.758583\n",
       "32   2.2        5.5    2.0  0.912037   0.982609  0.831683  0.829982\n",
       "33   2.2        5.5    3.0  0.953704   1.000000  0.827586  0.882227\n",
       "34   2.2        5.5    4.0  0.898148   1.000000  0.698630  0.778126\n",
       "35   2.2        6.0    0.0  0.967593   0.937500  0.970000  0.802222\n",
       "36   2.2        6.0    1.0  1.000000   1.000000  1.000000  1.000000\n",
       "37   2.2        6.0    2.0  0.990741        NaN  0.990741       NaN\n",
       "38   2.2        6.0    3.0  0.763889   0.869565  0.751295  0.412336\n",
       "39   2.2        6.0    4.0  0.902778   0.923077  0.900000  0.670728\n",
       "40   2.2        6.5    0.0  0.944444        NaN  0.944444       NaN\n",
       "41   2.2        6.5    1.0  1.000000   1.000000  1.000000  1.000000\n",
       "42   2.2        6.5    2.0  1.000000   1.000000  1.000000  1.000000\n",
       "43   2.2        6.5    3.0  0.921296   1.000000  0.919048  0.489644\n",
       "44   2.2        6.5    4.0  0.916667   1.000000  0.913043  0.551677\n",
       "45   2.2        7.0    0.0  0.981481        NaN  0.981481       NaN\n",
       "46   2.2        7.0    1.0  1.000000   1.000000  1.000000  1.000000\n",
       "47   2.2        7.0    2.0  1.000000   1.000000  1.000000  1.000000\n",
       "48   2.2        7.0    3.0  0.995370   1.000000  0.995349  0.705460\n",
       "49   2.2        7.0    4.0  0.976852   1.000000  0.976190  0.729704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeWAU5fn4PzOzs7vZzbJJIOEUi19BFBSQuxRRVDwqgkUORSAeKA2IbfVbLq14IEpt+7Na6lErWFEB+YKiWO+DUgW0igW5VJRTEpJssslmr5n5/bHZyW72yCbZHIT5/JPs7uw77zs787zP+7zPIWiapmFgYGBg0OYQW7oDBgYGBgZNgyHgDQwMDNoohoA3MDAwaKMYAt7AwMCgjWIIeAMDA4M2iiHgDQwMDNoohoA3MDAwaKOYWroDkZSWVqKqTeOW3759JsXFFU3SdmvDGGvbxBhr26QxYxVFgexse8LPW5WAV1WtyQR8uP1TBWOsbRNjrG2TphqrYaIxMDAwaKMYAt7AwMCgjWIIeAMDA4M2iiHgDQwMDNoohoA3MDAwaKMYAt7AwMCgjdKq3CQNDAwM6oskiQiApoIgggYoitrS3WoVGALewMDgpEWSRHyeIGtWfEZZaRXO7Awm5Q/CYjMZQh7DRGNgYNBKkCQRkyQiCSIVbi+SVLd4EkAX7gBlpVWsWfEZQhP39WTB0OANDAxanIZq4pqKLtzDlJVWoRnKO2Bo8AYGBq2AhmriggjO7Iyo95zZGQiGZAMMAW9gYNAKaKgmrgGT8gfpQj6s+Z86WWySY5hoDAxOQRJ5nkS+b5LFUAJARUMUBVS0Jtu4DGvikUJe18SVxN9TFBWLzcT0gmGGF00cDAFvYHCKkcjebXPIeNwB1qz4jEyHhYt/3ptXX97RLN4pYU28dp9S0cSj+pNkMjgVMQS8gcEpRiJ794yC4fr7l43rowv3yGOmFwxrkj7V1sTNFgl/QDE08UZi2OANDE4xEtm7VVXT38+wyc3unaIoKkFFRdFUMh1WQ7ingTo1+MOHDzN79mz9tdvtpqKigm3btkUd9/jjj/Piiy+Sl5cHwPnnn8+9996b5u4aGBg0lkT2blEU9PerPIEG2cQNWhd1Cvhu3brx6quv6q+XLFmCosT/hcePH8+8efPS1zsDA4O0k8jeLUg17295/xvGTekXY4M3vFNOLuplg/f7/WzcuJFnn322qfpjYGDQxCTyPPH7laj3TbLIjNnDm8WLxqBpqJeAf//99+nYsSN9+vSJ+/kbb7zBv/71L3Jzc7n99tsZMGBAWjppYGCQXhJ5nkS+r/gj/jfMMiclgqZpKa+6Zs6cyciRI5k+fXrMZ0VFRWRlZSHLMlu2bOGuu+5i06ZNZGdnp7XDBgYGBgapkbIGf/z4cbZv386yZcvifp6bm6v/P2LECDp37sz+/fsZMmRIyp0pLq5osuriubkOiorcTdJ2a8MYa9vEGGvbpDFjFUWB9u0zE3+eakPr169n1KhRCTXy48eP6//v3r2bI0eO0KNHj3p01cDAwMAgnaSswa9fv55FixZFvTdz5kzmzp3Lueeeyx//+Ed27dqFKIrIssyyZcuitHoDAwMDg+alXjb4psYw0aQHY6xtE2OsbZNWYaIxMDAwMDi5MAS8gYGBQRvFEPAGBgYGbRRDwBsYGBi0UQwBb2BgYNBGMQS8gYGBQRvFEPAGBgYGbRRDwBsYGBi0UQwBb3DKIkkimiQSFAQ0SUSSWufjIEkCNs2Pt7AIm+ZHkoSW7pLBSYJRk9XglESSREo9AR5asY3C0irysjNYmD+EbJvcqnKeS5KA7Cpi99JH8BUWYcnL5awF8yArF0VpNUHoBq2U1qmyGBg0MUHQhTtAYWkVD63YRrAZzl2flYMl6GNvtXAH8BUWsXfpI1iCvmboqcHJjqHBG5ySKKqmC/cwhaVVKKrWpA9FfVcOghrUhXsYX2ERghoEydyEPTVoCxgavMEpiSQK5GVnRL2Xl52BJDatfbu+KwdNNGHJi87KasnLRRMN3cygbgwBb3BKYgIW5g/RhXxYk25qsZls5RAPn8nCWQvm6UI+bIP3mSxN3FODtoChBhickiiKSrZNZmnBCBRVQxIFTNDkG6zhlUOkkNdXDnE2TRVFg6xczl6yBAkVBRGfyWJssBqkhKHBG5yyKIqKoKiYNA1BUZvFe6YhKwdF0fAIZqx5uXgEsyHcDVLG0OANDJqRllo5GJyaGALe4JRDkkSC0GICVlFUBKofPkVDabYzG5xqGALeoM0jSSICoKmhEmfuQJDFz3zaKgKcJEnAEvQhqEE00WTY1w3SSp0C/vDhw8yePVt/7Xa7qaioYNu2bVHHKYrCgw8+yObNmxEEgVtvvZWJEyemv8cGBvVAkkR8niBrVnxGWWkVzuwMfj6lH9kOK4WlVbqb4tKCETSFg2Sy1UJri1KNnAgFETQatrJJVzsGjadOAd+tWzdeffVV/fWSJUtQlNhF5caNGzl48CBvv/02LpeL8ePHM3z4cLp165beHhsY1AMBdOEOUFZaxRsv72DKuHO4b0VISWmqAKe6gposQZ8u3KEmSvXsJUvwCOkLYkpF4MabCCflD8LmkPH7lZSFdqJ2LDaTIeRbgHp50fj9fjZu3MiECRNiPtu0aRMTJ05EFEVycnK45JJL+Oc//5m2jhoYNARNRRfuYcpKq2hnk/XXTRXgVFdQU9Io1TQRFrjPL/+UJ5Z+wPPLP8XnCcakR4g3Ea5Z8RlKQMNsllJqI1k7Rnq0lqFeAv7999+nY8eO9OnTJ+azY8eO0aVLF/11586d+fHHHxvfQwODRiCI4KwVserMzsDjD61CmzLAKVFQkyCASRLxmez8z30PkNmrp/55uqNUUxW4iSbCCrcPTUldaCdqRzOU9xahXnfSunXr4mrv6aJ9+8wmaxsgN9fRpO23JoyxhtBUjSk3Deblv2/XTQZTbhqMtZ2ZZ+++FNkk4rRbEJtAgy91e2OCmob16UjQE+TF52pMGBNuuR3+9jgBl4uzF87H1iEbuxhf96rv7+oq9cQVuKIgRLVVUe7FmZ0RdawzOwNPhR9HO0tKbQBUuOO3Y7ZIZDrsUcdqqkqgrAw1EESUTchOJ0LEuI17uPGkLOCPHz/O9u3bWbZsWdzPO3fuzNGjRznvvPOAWI0+FYqLK1AThGw3ltxcB0VF7iZpu7VhjDUa2SoxvWBYlP3YXxVAAIJBhWJvoEn6JkkiC/OHRNngb7v6XFY9+WmUNrxu7R5unL8ISfHjM1nwFFfGba8hv6tJEuMKXFXT9LYkSUQJqEycMZC1Kz/XJ56rJ/dj6+bvuHx83zrbiBzzpPxBMTZ4f0CJOja8wby31gZzoHqD2biHU0MUhaSKccoCfv369YwaNYrs7Oy4n19++eWsXbuWMWPG4HK5ePfdd1m1alX9e2xgkGaiNvea0ek8XlCTmMCEEdREfII5brqCxqBBXIEbeRYBePGZbfzkzPbccOtQKiv9eCr8bN38HaPGnIUg1d1G5JgtNlPMhFp7g7W5NphPdeol4BctWhT13syZM5k7dy7nnnsu48aNY8eOHYwZMwaA2bNnc9ppp6W3twYGJxm1g5qEBBq1INIkk08qAjdsN9+x/TAnjlcwYvSZZNhkLh/fFxUNv19JSWhHnrPmRfx+GWmQm4eUBfxbb70V894zzzyj/y9JEvfdd196emVg0EZJRaNON3UJ3PBGdFlpFUcOuliz4jOc2RlMLximfzfdq6BwGuRIIW+kQU4/gqZprSZszrDBpwdjrDVERooimUAUIeBvkajR2hG1ggCqpiXVhiP7b7KYqdDkpH1uSGRsS/iuGzb4GlqFDd7AoDWiqRomSYxrOogXKdpz7hy+f/4FAi5Xs0aNNkSI1jfStaGRsanazdNJZBpkI01D02GkCzZoEiRJxCSJSEL13yR1RxtzjsIf3QkDcOLVM93/5yfoNuGatNc2lSQBm+bHrniwaX4kKdrtsiEBQInqsVq1QNxzNaZ+q6KoBBUVRav+2wxRp+E0yJWSzUiD3EQYGrxB2mmuJb8Aun871AjN6QXDQp8n2MgzZWbq/6djUy8VzbkhAUDx+i9nZaGWlbJn6bKYcwl+Y+PSIBpDgzdIO/G01Y/e3ouIoGv0ZrOUsoafaDVQl9BMVM80WFGh/5+OTb1UNOdEEbVCkicwXv9PmzxRF+61z2XUbzWojSHgDdJObcHbtXsWQ0eewcrln+imFI/bz1sbdkWZVsxmKUbQJ8ulUpfQjFfPtOfcORxetz6ttU1TySkT9p4J9zcV75l4/c/o0iXhuVpb/da6zFbJ0FS1wd81qMHwommDtPRYTZLI88trojUn5Q/irVd3xfh+XzauD2tWfKa/vnJCXzIdVmyOkKeIoqgxbYWPnV4wDA0IeJWoNAS1TUHN4UVj0/zsXrQoxuUvMmhHkkQqAwrFJVXYzBIev0L7nAzsspTUbFXbiyYYVPl6YeJztZb88nV5ydT1XUvZCXY/9HC9v3sy0pReNIYGb5B2amurtkxzXFNKRkRGx7LSKsxmE2tWfEbhUbeupUeuBrp2z2JS/iDGX9cfoXp7Mq+Tg+kFw5iz4CKmFwyLsfNHbuRVYqZSNaV9Uy8lzVkSdOFe7gnwwtt7WfzMp9SVNzKy/+bsbLxS8nO1lo3Lxmz4WoI+XbjX97sG0RjGOYO0U9vtThSFuNGbVZ5AzOtIQT+9YBhUm2EyHRZGX9mb11bviNLWyYJgWKC3UO27ulz+JEnE5w7w0bqdet9vnXweT2/aXe889CeLe2FjIlVT/W5rWa20ZgwN3qBJiHS7U9Hi2J8H8uX2g/rrqyf3Y8v730QJek2tWQ1cMKanLtyhxmOmsrJ1aHXJNOd4m85vrv6KG8ac1aA89K1FS09GYzZ8U/mu7rm0aBFf3FbA7kWLkF1Fhq2+FoYGf4rSnOXZ4gXSiJLA5eP7culYlZITlby/aQ8Vbh9XT+7H+5v26JulwervWqyZcc08SrD1JxpP5O3TrYOdJkpB0+KEzVa1bfA+k6XOhGo+k4WzF86PscFHftdIVpYahoCv5lRa7qXLT70+7cTkMlFq2sjt6GD89f2jBH2kh0l4szWemUcyiRBs3SIyMtdLGGd2BiZJRCVxJO7JTGNMSYqiYTu9e9LvGsnKUsMw0dB2lnthtzRvYVFS17J0lVVLRzuKohJQFARJoEPHTK6ZOiDuZmkiN0O7velcABvj5hdJor4LEklL4dU+v6amR/Cna1x10RhTkiCKSb9r+PynhnE1aBvLPUkSsFS68B0/jmS1oni9WDp2xGfPin040lRWLZ3l2erKVpgoX4rQBJWYoOF5XeKRqO+qosWdIKcXDIt7/rMXzkdydmjUyjKd42pJGmMCOpUwNHiap/hxU2PVAgRdLr576hl2Lvod3z31DEGXC6sWW62oIVGV8UhXO6nSnPlSGuPmF494fU82QcY7/+6HHm60q2C6x9VSKIpGoNoENOCp5Zy9ZEmb9ZNvDIaAp20s90QlwP4/PxGTWEtUYgV8Q6Iq45GudlojTT3pS5KAJGoJJ8imOn9bUGbCnAzeRC3NySPBmpC2sNzTFDXug6upKkjRx6YrPWxLpJltLpqyIEXYTHJo9RomXDuVda/sjSn+0VTnNwptnFoYvyonT/BIMjSTHP/BleS4x6ejQo8kiQRBrzdqqt1uC9MYz6imnPQj93wCJaVMmnQ9UlY2lvbZKAgoipr4/GYrktrw69wWlBmD1DFy0bQRGpP7o2HnEyn1BHhoxTYKS6vIy85gYf4Qsm1yswr5RL9rXdcj2eQUnhhEQUPQNFRVjRud2tDJza54+OK2gpj3Bzy1nErJFjUGq+pDDQQ5dKKKZ9//gVK3j4X5Q8hymBGq+xKvH8kmt5PBJbitP6+RGBWdDOokchUioaIgNumDGwRduAMUllbx0IptLC0YUW93y6YgmWeUz2RNODmBFtfLJHKibOzklrqZRKAMC3c/+7l+nSF03X854Tw65tgIBFSW1OpHh0wZsaQwoadM2Hat+4u3MuFukD5S2mT1+Xzce++9jBkzhrFjx3LPPffEHPP4448zfPhwxo0bx7hx44wC3C1A+MG15uU2+aaTompRQgdCQl5JcQXW1L7YyTYTE01OQVLzMkn2/VRINa1vECh1++JeZ6vZxPESjy7cI/thCnjbhKeMQeNJSYP//e9/j8Vi4a233kIQBE6cOBH3uPHjxzNv3ry0dtAgdWSzhF+BYycqkSQJswQBf9NEeUqiQF52RpTwycvOCOVWSSEdbFP7YifTkpNNTqlESCb7fioPVKp7PoqqUVbhj3ud3Z4AuVkW7rjqTLKsEi6vwvMfHWLvQRcoRpSnQYg6NfjKyko2bNjAHXfcgSCEtKwOHTo0eccM6odslij3Bjl4vJzisioOHi+n3BtENkt1f7kBmICF+UPIq3bzC5sHUhFwzeGLnUhLFiQRZ7CSZfn9OKt7ln58eHJKKdFV9eQWiT65pUgqLn6SKPDe9h+YO3lA1HWeO3kA23cdI9fnwv+XZRya9xv8f1nGby7uzC9GnUHQbKfno/+PM+6+l8xePeOOweDUoM5N1j179jBnzhwuvfRStm7dit1u54477mDQoEFRxz3++OOsXbsWp9NJbm4ut99+OwMGDGjSzhvUUFJWxeGiCh57+QvdHnvHlAF0y80kx5lRdwMNQFU1yip9BIIqsknEabcgpiDkvIVFfD5zVsz7A595Emst4doYNFUlUFaGGggiyiaClR6+vu8BfdXQ7Ve/4dF3j1Hq9nH3TUM5vVM7BDQ8PxyMSnR19sL52E7vjiCK+rh/+LGcB/++Vb/W4e+nMv5UCZ9n1T93c9XPzqBDVgY/Flfy8tv7uHl0dyr//HCUpp49bAjZ025jzYrPdbfLCdeeRfn6VZw+ZXLUGJobTdWorPQRDKqYTCJ2u6XJopANaqhTwO/cuZMJEybw6KOPMnbsWHbs2MGsWbN45513yMys2b0tKioiKysLWZbZsmULd911F5s2bSI7OzvlzhheNA1HlUQWLt8Ss5R/qGAEYityXYTUKiClSqq/a6Jz9n5oCR7JGteLJpn5pLlcRCPPY7Oa8PtVgqqKM1gZ44lzxt33suatopikZvkFQ0P53VpoM7Uhye3a+vMaSYtWdOrSpQsmk4mrrroKgH79+pGdnc2BAwdqdTIXWQ75XI8YMYLOnTuzf//+BnXaoP6oKnHtwmnKT5VWWqJ2aCLbuqgEEWqlPUjFfKIoKoKiYtK0mO+nk8jzODOtoCiYNC2uKUnKyo6fUlkVWtQNMl3J7QzqT50CPicnh6FDh7JlyxYADhw4QHFxMaeffnrUccePH9f/3717N0eOHKFHjx5p7q5BIkxSfLuwqQUyYkqSiCaJBAUBTRJjCmm3RB6RZLZ1SRIxSSKSUP1Xav0ZPOJNkpasds2aGyhV0pmUzqB+pBTodOjQIRYuXIjL5cJkMvGrX/2KUaNGMXPmTObOncu5557LvHnz2LVrF6IoIssyc+fOZdSoUfXqjGGiaTiSJOKqCrDkuRqf6EU3DiEro3kDj5o7ACrV31WSBCyeMtwnyhCsdjRvJY4OToKOLDzuxufGbyj1KbxSe6y1TUlBi7VFx5KIZIXTg4aJpklNNEYkaxsibK9FEEDTWiR1gCaJLIizF7C0YARCiwr4+HbgDJvMyuWf1Ev4JGq/vhWy6mubTmWs6arUlU4MG3xyjEhWg5RQFBWBmhumJeocNdZHPFXCgsxV6glVRCK5IEtkB542a1ijzQcNrZCVqE/TC4ZVtxutoddV8CN0vLdmc1i0VKdlaLrUBHVNKOHPbXaZGQXDUVWt1Uw8pwKGgDdIK40JgEr5HPUUqJIkgKrFFeSiKMQtpyfUo1hqXYI6Ecls0/Ut+JEoeEzKyUuatqAxxPsdJucPJMMh4/eraSsNadBwWv9ukkHKpFqyrylpTABUqtTHKyMs+HyHD8bfgJQan9O+oZuIyQqm1LfgR8LgMb+nyYLK4v0Oq1d8Dv4gkiQgIsT9nUTDf6bZMDT4NkJrKcWmKCrZNpmlBSOazEe8PgI1nHRMzspiws1zYnKvK4rW6Jz2iYpq17UKCBdMqa3hatS/qHSi4zVFQc7KosfNN2LKzCRYUcHhdevTkrYg0e/gc5Vjd9rwi5YEv5OhvTcXhoBvI7SmurLhvQATgKKlfS+gPgI1LPjkrCwyAy5m3HI+KmAyywRD1uNo+7RYf/t0MkGdjGQFU+pbmCPR8YLZzE+m36BX+7Lk5dJz7hyQzdBIOZvod1BcpQgOM5Jkjvu5JGgEW41rR9tGWrx48eKW7kSYqio/TeXTY7db8Hj8TdN4K8Cs+nB98SVn3HoLna64jJyhg6k88D3thw8lIMYv+nGyIogCvft04tu9Rfi8QV2gSrJIbacwWdDwFf7Iadf+gm8e/wvHVr+Me9sn5A4eADY7ptIi9tx3P4dXr6V066fkDR6AZrPX6z7UNA3ZItF/cDeG/KwH/Yd0Q5LF1FIHaxqqpqFR/bf6xKrJRN7gAbi++AKl0qPb4H22dnH7Fu/4sxbMQ7RY2PNQTUoDpdJD2c5d5I4eTaB2qa96IogCZ/fpyDcRv8OEa8+ibNP/kTVoEKIIPX7i5Lvvymo+n9gbu91EQEtuHW7rz2skjRmrIAjYbIkVOMNNso1gF4MEjh6J0dTkLl2pVNveQi3snSEKQrWAjG9WkSSBDH8Fu+5ZHKPd9l3yADsX3ZOWlAlNQW3vF1uHbE4UV6Z8vM9kweqPTWkAscVFGkqmrOLzKvjdlSiuUkrffZOuV/0cuUtXvIIcEXtgQ/N6cHRw4rM561wltfXnNZIWTVVwqlBX9GWrR1XjFt1ulbkK0oCiqAQVFWe2jWCSVAGKoqEhJLRPt+YC1LVTJtSVKCxeioWmLiiveb388IdlSMVHsWVIdLzoQr5//gUI+FEUDZ/NiaNLRxxZGTi6dExJuBukj7an2jWA1lJ+rlEkyAGOYuQAT2iflqRGFaBujUFFtWnqGqyaaCLgcrFn6TL9PUteLshmbIofwR9aTXjN9pBgN4R7s3KSqalNQ2Mr9LQGmlpTO5lJmNzMbGtw0rOwj/fzyz/liaUf8PzyT/F5gq1q5Rc22ZgcDvoueaBJ8v7Eu7Zn/+5ulDIXuxct4ovbCti9aBGyq6hF3HZPdQwbPBAUBG5d+l7M+08vuBhT67k8SWnuotuthXrloqm2T4c8SNTQ6ibi//pEeTYkv0pjqY+ttjnvh9q2f0GArxc2Lh20YYNPDSNVQQqYRDFu9KVJFEFpiYD/hiHKMmfcNhPJakXxehHltuU9k4y6wvHD9mnJbEku+FIUfq09Q2K63GZTSXNQu4i3XfEYJQNbCYaAB0QJ7pgyIKYakiiBepLId0vQx+77H2wxj5CWtEfXJ8grXYKvocFNzUWqgVJmWcTi96ApCoIk4TPb8AciCp9UuvAdP64rDZaOHfHZs5KuAurrw2/QdLQeg2EL4g+oPP/Gbm4Zdy5LC0Zwy7hzef6N3fqNfjKQ9IFuYpLZo8PpE+yKp8nSJ9Snxms6rpMkCVgIMDl/YKNSHITbquv6NCQFRSp7MmZZRCo+zs5F9/CfWbPZuegepOLjmOWQWMgQFQKyjaAzD0+Vwo/vvEvQ5cKqBZKeuyUKuhjEx5hSCSXIKnV7eWjFNv29dCfIampaUmtKlBtmRsFwJFd6E13Fy7CYsFqTGkAyR5sUEl0n3eujjoyL4dXC19XpDyZPnY6lSzcEkwkVrV6rllRWHg1NQZGK94zF72Hnw8uiJsY9Dy+j75IHUEw2yioUVq/4IqK+61SOrF/FGTffCELy+0pytKPP/YsRJBFVkvEKcpveC2qtGJushDTQyoDC8RIPVrMJrz9IxxwbdllqpqIPjU/n2pKbrJIg8sTSD2Lev33BhXy74K64AUYeU0Zaxnj2wvkImY64m3pn3DYTOScn6hrEbeN3d6MGAildu/rUk61tthIlAVXR9NcWAnw9b37Sthpav1aSBDAHMXsDoZq8ogmvFJ0+WFQCeH74gcPr1lOxr6a85vlP/gWvxRF3E3nSZblknZZHhWRP+Tc6a8E81PZ5qEpqJjxJEsgUAgR9/rSnN26NGJuszUAgoPLXdV/VVEPKHwJy40K5UyFdScIURYPqMngSKgpisz0YiezRkqDF1az9xcXIFku9xxjPfr77oYc55+GlMdrqmXMK+OGFFwm4XJy9ZAk+k1UXtkp2R85+5GEEvx+k0G+8N2L/Imzi6bvkfhSkqOtYl21bF54ilHkkVq/4nLLSKnr1yWPUmF6sqX4dTq0rZ2VFtVfbTl7fpGMQuqfKKOXRD56kyFNCri2Hu0bMIke0YtUCqK5Sdi9dFnOtKvbt1+MDEm0iS1nZaFLs5n143FJQYWet3+jQ6jXkTLtNvxbJ0gaHn4evWjhpXlvBsMET8oNfUssPfkkz+cHXx35cF2FvBmtebsJi0U1BONlWpD16wsTeqEd/iGsHDpSVNWiMiYQdgQCBrFz6Lrmfvkvup8fNN+oCy1dYhCgStUew8i+fcKQ4wJ82fccxn5QwSMxXWBTjw528tmv1ZL1oEeXHinWBBtB/cHdduENNat2OU6fHbUu/tiYp/vlMiZUPRfbz6JaQcAco8pTwyq7XEUsK8R74jj1Lo80y3zyxnG4TrgkJ03n/iyabE6YytmS1wytF29Ijxx2+bpFkX3JF1LVIlt45nc+DgSHggeRViJqaltwcTReRWRFvX3Ahk6/qTPHfHueH51/gzDkFUZttPe+4HcluD/1FqdemqyYlEK6ShKJoKEjsf+xx9ixdppscLHm5+EVLzB7Bm6u/4rLBp/PQim0J2w1WVMQImGQbiJHCSe6QG6UBZ9jkuBqxpUu3pJuRVRaRrnfOiTqm651z8FoSP7qKpurCPcwVnYeyd+kjSFZr3PvNdnp3zrlnEcc2/RPN5407aU/OHwhmU1zPpPC4gxUVMddSyspO2aW0LTwPrYmUTDQ+n4+HHnqITz75BIvFQv/+/XnggQeijlEUhQcffJDNmzcjCAK33norEydObJJOp5vmqEKUiNbkUtaYvYDwUtuuePj63nv093944U9pDgUAACAASURBVEV63HwjttNOw1tUhGi1sPeRR6Ps34I1I6VAI49kpcsdv+HoY3/Uv9/ljt/gkaygqAk3FgOqEFfAtLPJFJZW4ZGsCU08EG0SiTSF1b5OkcJJFKLNVlWeQHy3SpMpblthNOCFos1cMe9WOko2yhQPLxzbTH7XyYl/R0Ek15YTJeSz5Uy+jxDAte83zw8H2bN0WejemzIlYSpjvz9WKkeO+/C69Zw5p4BvnliuX0tLVruUXUpb0/PQFkhpk/XBBx9EFEUWLFiAIAicOHGCDh06RB2zYcMGNm7cyDPPPIPL5WL8+PG8+OKLdOvWLeXOtOQma0vlomno5mgyYdyQTZt4/ei9YB6Sw4EmmfBjTlpPU7fBorBz0e9iN1YfvB9NCbLr3vv1z3IvHk3nKy5j77KQwM8eNoSut8xCFSQkEcwEIBjUfbQxSRS7AzgzTKiSGUUTQsdJCn7VRFAJbTqZ8YPfp18XSRIpPOrGbDZR5Qmw5f1vqHD7mHLLIILuMrKy7KhmK7LPg6YqVB0+wqHVa6NWAX0fvB8EIcpPvDaRG6LnPfZHArZsKiqDeCr8HDxQTN8BXVm7MtoObXPIaAqoqoYoCoiSgEnx6f0Pmq2UqCW6yWVwl/OY1fsXSApxJwRJErAqPlTFzxFPEc9/+yYubzkPD5vL3oX3ImdlcfoN10cJ4J5z5/D98y8QcLkatDFfeyM4s1dPTps8kYxuXVFFmaDFisedvHRf5Ia0pAU58rcnKf102ykRkd2Um6x1CvjKykpGjRrFRx99hN0ef+cc4NZbb+UXv/gFl19+OQD3338/Xbp04ZZbbkm5sy2ZLthsFjFrNQWL/YI1rrZSH1IN/qmv5pxoUhA75CF5a4JWAhYbXr+aUvuJvDXOnDuHCnM269buqXk4bxyILVPWr0+4P0UffUznyy4FQUQQRfzl5Rxe+wpdx43DtXMnHS8cha8opEVW/HCQjpdcjOvQjwhWO7Is4DM7WLPyP/qm5Jirz0FxuwmeKKL03TfpPnkipvYdcLnVqA27iTMG8vE7+9i3q1Dvn8UpYFFNSEEfLo8Ydfy4Kf3IdJgp37QB99df85MbZyBZLOx5eBlyVhZn3HYLlRV+BKsdzVuJPdPMd0/9jYDLRe/5v0XL7UQwqMX8rmazCP4git+PTzNHC7QZ55PtEPFqMqoSEuaSLFBR5o86btyUfmSYVH78yx9D56ueZAU0kCSCrjL21PZQycnDH1Cj7gs5K4uOYRdOsxRajZ44rn922uSJZHTpAmYzmiBCoOEeK6koKcmehbi1XW8ciNOioKrofWroClOSBGyCD0ELogkmPFrjnA/SXcS8RQX8nj17mDNnDpdeeilbt27Fbrdzxx13MGjQoKjjxo4dy5IlSzjvvPMAeOaZZzh+/Dh33313gzrenGiair/wIMfXPkywrAiTM5eOE+djzuuOICS2dWqqSqCsDDUQRJRNyE6nntJVUzUKf3Tz8t+36zftlJsGk9fJgSA2LtjHX1rKV79dECWMz7zr11h7n4vPVa7n5e4+6Vqsp3XDe/holFA4e+F8bKd3j0o/6y0s4vOZs2LO1eepv/HPTfvpP7g7GTaZKk+AL7cf5NJrepOdlYkoiPhLSzm84TVyR/6MvY/8vmYFMP9/MWVlQVBBU4JUHT3GodVrkbOzOH3aDZRjZ83K//CTM9tzwZheuMu8eCr87N31I+cN7MZrq3dE+GCfhf+T92n/83GsePqzmOX+ZeP6sGbFZ/rrGb8cjOwpI2DOZOUzoUmja/csRow+E1umGUemCVNZEZqiEnSX891Tz+ArLAppn3fORxUkEATQNERN4cSaVTiGj8TUIRfJ0Y7P/v093Xu0x5mTQUaGjCgJeCr8rH7uMy4b14e3Xt0V08cZBcMpOu7m6x3HOKdfZ/I6OQj4FbzeIBXlPn1lceWEvnTIsXDw0YcJuFycOXcOXkXE0vU0fEcOUf7xBziGj0R0ONG8lThO70hGVjZBVxlf/XYBclYW7WuVJ5xy02By8+wE3eX6/WpytKPKGyAQUNFUDVmWsGdakt6fmqpRWekjGFQxmUTsdgugUXX0GN4ff9QjXq2dOpHRpXPU81D7e+HzVLi9PPvYlpjrdfMdI8h0WKu/r+L54SC7q4uXJLqPY/rbwGc78fgb1o+Wok7DVjAY5NChQ5xzzjnMmzePHTt2MGvWLN555x0yMxPPHA2hpTR4h8lP6cerMV9+M3KGA6HKTcnHq8kecxtVipxA60iutZgkURfuELL5vvz37XUmo0pF27Ar/ijhntmrJ1qPvqx46rMIgTiVg2tWccbNN+nCHWpcC2v7UdsQE6TUFRk68gxeW72DTIeFC8b05JKrzkHQwO2pRPWJoJroMPYaDj3z16jzHFy9lu5TJnHw5TV0HH0RstNJz1/dTsBdibu4nDWv7yXTYWHQT3/C88s/0ft+7fSBbH53X9S1W/fKXqbfdCW+svK49vQMmxz1WlMg6CpDyW2nC/fRV/aOnjQm9sahlEdtPJ4+9w48AVi7cluEOWEgnWfcRHFRJZte24PdYeaCS3vx8Tv7GDryDNbUEuqJNlTLSqv4/JMfor4b2Z+rJ/fj/U17MJtNKIKJTgW/pmzjK1Q5u/DRu9/QX6rEmdsVxy9uqNZ2D1avYDrjk91YfaH7ouutBaypFu6x954JBBOSJqIUe6h0+3j15R0RY43vvhi6N2M17Un5g3DaNL6+74GEvvpxNfT8gWQ4QqtASRDjXi+/T6HIG3pmbZpfF6rJ7uPaOEx+CquFO0CwrIjjax8mb+oS3MH6p/BoaD+S0aIFP7p06YLJZOKqq64CoF+/fmRnZ3PgwIGo4zp37szRo0f118eOHaNTp04N6nRzI4gaVSPG8sDuDdzxr8d4YPcGlFETcVWQMB1sMncuSRLrlYxKkgQcJj/tzD7s/iIKVy3iyF8LKFy1CJsvNs1qbVe9vEnXx7ihrXtlL9mXXFFnUQtJEjFJIj7RSs+HHiF72JDQ+Ko3GlVF04X76Ct7s2ndTpY/8iH/WL4VT6nCWxt28fjSj3juye20u2Yqmb166ufpOPoiDr68hi4/v5IDzz7Hf+cv4uvFDyDJJkSHk7LSKkaMPpNXno/u+yvPf07/wd1jrh2SjOIqjeu+V+UJRL2WJJH9f35C3+wcMfpMXZjq12jtHrScTtGeH3anbicPH7dmxed4q4K8+vIOLrnqbIb8rAdrV4b6GG4zUqiHN1Tj9bH/4O4x3w2f57XVO7hgTE/8/iClxZX4MJE3dQZIEiMv6RWaQEqqYjyC1q78D6JfJmi2kz1siH5ta18/VdPAGkCSBEQEXCUeXbjXjDXWfVGSBLAGQNDiRiwHNSnpPRYv0nn1is8hoCBLEqIoxL1ekQp2Q71rBC2oC/cwwbIiBK1hXjknm5dPnQI+JyeHoUOHsmXLFgAOHDhAcXExp59+etRxl19+OWvXrkVVVUpKSnj33Xe57LLLmqbXaaZSEvjD56ui/IZLqhRWP5fYdzdheHy1z3VxUUWdNy1Ua+y+kFAP/vgtx195JErbKFz3CDYh2ge4tqteIjc0KStbL2oRSY3fdnQOmRVPfUbOtNs4/9mn6fPAYo6+sYlAZaUuiGsLpDUragRxeFLJm3Q9mb16csbd9yL26E3n/Fso+WIHXW8t4MxH/kjXWws4uGYtZpsVZ3ZGQm3XlhmtDYWFdum7bzLh2rOic8DMGMiX2w/qrydcexZmtSrktneikHFT+mHLNMcXegi654clLxdV1eIeJ4ohT5wNL32Jw2lNKtS3vP8NV0/uF9XH8df1Z8v73+jfSTTunA52bHYzX+84hskksfKvWykrqdInwWSrg+eWbyV76kwkQaFXnzwm5Q9iRsFwJuUPolefPH4oP8jiD/+AR6ogqCqYzaY6lZBw0NTiD/9AcWVp3OMVTUia9yaRshNUBVYu/4R1//gP46ZEX68pNw2OyusTqdSE76+ej/4/AmZ70hz8mmDC5Izum8mZi1ZHqoWE7Z1kdRdS6tV9993HwoULeeSRRzCZTCxbtox27doxc+ZM5s6dy7nnnsu4cePYsWMHY8aMAWD27NmcdtppTdr5dBHUVLKs7fjl2RNwVruiZcqZcW9KVBWb5gcpvjtXyOd6K5kOC1dP7he1BI+XjMom+ChcFxLqojUzibZRI/AURUPKyaPvQw+gKQoBc2ZcNzSLsx2YgvT6VQH7/l+N10Tval9rESGuZjVj9nBU0cLpt8xEkcxJBXFt04ipQy7tb55TbSI4SK8+eVxw6VXVm6chk8Kk6TOx2iSm3HAuUoY5bt8zHRb9/bCZRPJV0PXqqzmyfhWTLrsCKSsbS1Y73J9uYdS53bjop31R3eWUrl9FzrQbyB42BFXVyMrOQCN+tK1olpFzsvnhhRdDqZartcnax4VNh2Fh36tPHja7mfw5P9X3DcK/95GDLrZu/o4bbh1KVVWAKo8fU3UCr/BEkMhtUpJE/rl+FxeM6amvJOJNJLW/V+UJhCbd57/gxlmDGDUmJypqduKMgbx2dCNFnhIKK09gCrjJ8NftvqjIfh79MOTB4w64ExwvJs17Iya4piXFHn1yeu+NPVw5oS/tczMRRMjKsnGiuEI/PqzUHFq9hnbXTNXvr7rMSh7NQt6EefozltFzCPaLZ+FRTJik+mc9beoKWenGyEUDmG1BvIePcujRx/Uf7X+WLOWt12M3F0eda+XI08sT5i8JOvN4/KFQXpbwpl6GTQ4JiTjJqNpJHo78NVQUueO1v6X4neeihLzJmRtjL9S1/oibVvhpdCj45Pzz8W15j7wLfoZr8wrs51yElOFEyszCZ3HgD6iYBIHHl34Ycz3mLhiFKgrVngshLb/C7WXTup11bm7mFwxnRbU9HULBMvE2HKf/chi+qgAfvh1ri56UPwjJBBXlfkyyhN1uxpohQlUFoigiaKAFg6FEVqqGWlnJnodrQu97zp2D6+s9mH86mjUrv9C9cmqnChh/XX8EEeyZFmQJzPjRLDZcpd4Y4bh9y/fs2H5Y99JBI+qYqyf3Y//u4wz66U9QVY3S4ko+fns/Rw66oq7Vl9sPJrTBh8/z/TfFTL11KMsf+TDmGnbtnsXl1/TBU+nHbDbh9wex2c38c/0u/Vy3/3Ykzz8TuxE9cmpnHt72OIsv+jWrdmzgtnPyUavEKBv8xBsHYo/wkFIsPua+GYpr6JnTg/wzp/L5B0foP7g7tkwzmQ4LkiyE/OYTeJaYzRKlRZ7o88wYyJv/t1Pvc5g5Cy5C0dS4z6skCUjAiuVbY++nJHtb+r6WCKUVkr4yr2tySMTJ5EXTOtcVzYy1SmF/tXCHkKmldNPrjBozttaDfj7u9S+GNlbuf5BzHl4aE6QiodGrT17UxPDJR99yxfhz4t4E4SVksKwI17/Xk/vzAoreWK7v+OdNmIdHC3kqhInU+gGq9m+jy4X5TL6qM4LVhuou5/hjjxBwueh40SiyL50ZvWkbzvctavG1WoJYBRU3Zj3gpZ3TwbRZQ6lw+/FU+EOT3ZhefPT2Pv17k2acD2L0cjyR5q8Ea1wdK91+xk46j3ZZGZQWV7Jp3X+pcPuYOGMgPl+QDS99ydXX9WX2B/cChHzBu16uT67n/eERvdCJGgyiAVkXXsyKau8ZgH27CgGYUTCc8jIvwYCCSRZ55fn/6L/vdTMHU+mqZP/OH7n+liGIkoAkiezZeaxGuOcPxCoLPP909MrntdU7uP6WIfh8QfzeIC/9bXvMmHM7ZdJ/cHe2b/me/oO7Y880M6NgOJqqgQg+qvjpxWcwakwvhIhAqbDJ57XVOwAIBlU2rdupb3pbrDIXXXEWH7y5lwq3D1WLbxJxyA4AvEE/Lm8ZT329gmnnXMvUWYPRNNBElZVfv0x+/0lAaGUWGTS1v+QA7xW+z9hLr+KVlf+JEpI2h4wPa42gjCy2EtB47409XDauj/5M+HxBKtzRpse68ukrigYJNmSTFVpRFA03ZkySyOrnPo363das+IzpBcMSfzlBe5EFTlqj5h7GEPCEtMHa9vSMPv1icoesXfkfJl02kqL33q/OgeLHY5dRNAlJEJACYBGCXHBpT9au/I/+AF469hwEQUCShBhNIXIJ6Tu6H9f2TXS6fjGaIKAR34sm3sZR2dZXyDzncvY8HOG+9bu78cmhYseCCJoWvRw1SwoTr+vN2pcifNyn9kGVA5SLIJgCyKoFVQridmkxyaIyLSpjrjiT0aO6opQUU/rC09hum51aBKdYE1165KALv09h1dPRmtnalZ9z2bg+VLh9yCaB+UNuxyE7cAfcKLk5emI1TVH46s55UdfjzEf+GCMI9u0q5NKrVFY88W8m5Q9i45qvon7fspIqfZXy6UcH9L5OLxhGr3M6Eiwq5NhjD9Pp5l/GFTJVVQHaOa1kZMhxx6yh6Zr4998UMyl/ICcqD/LcnlfZX/I9ENKS7xh4K0pQYVL+QNas+Fw3+UybNRRRFFm5/BN90ztyBTBuSj9sFjAlmLgFEXJtOeTZO3DXiFk8uuVJfvev35Nry2HWkGm8vOM19hcfYHq/a/XNOSlg1o8t8pTw007DdOEeHveaFZ9x5YS+ZDqscbVhQYQKt09f6QH6HkFtj5y6RGVjCq209ipcTYEh4AGhOqFTpJAPbVwejDqurLQK0dEOCNnbVZPAIfdRrCYz3qCfPHsHTEoma1eGbPDhpbTfGwSrCUEQkCUJQQppAYqihrQBS8gME9ayKzQLSjB8qyfX+sP4fvgvzgun0WfJ/ajBIIoscaJKZMNfPol6gCIfQI9ior0TbpjUGU22IZkklGwzP1aVUu5zs7foW0acPpgKl48P/nEw5qEOuwZOuPYsiteEknv1mHlL1IP75faDTMwfyNpa5ozKCl/Ug5pss3XKDefi8ahsXnWMstLvcGZn0PnGLqgZVnJy7FQWFsf8fpq3MqEtPdGeQqJNx9IqF7LfzcH5iwBQ3WUJ9w1UcwBJMTHpxoGsiTAFXDm1N698t4Hps6+h1FOGy19GiXyc5dv+oW/u98zpwU09p/HS8tD3ho3qwYyC4dURxBofHN1M/+zzKCut4rJxfWI2vV99eQf5BUMRRRg3pV+USWTclH5kZ9h44KLfgj+UqGzxRXdSXP1bv/zfkHDPteUg1vIEcFoc3HvRb9A0FdmfQVnp3phrZDabEmrDoiTok1W4P6PG9CLTaY5JhVCXqSScI6e+EwO0/ipcTYEh4AHNYqb3/P9lz8M1QTqJ8meo7vKQvX3hPI4LlTz7+Ut6StaCodOxS6HN2aun9CPgV/j8kx8YPup/WLMyOpLS7rAgyaIu5N2YqdlITX67Rmr9gj0L84VTENp3xi0EeW7vOj47+hXzh9xeLRATL0cVRcNrzsLRQUL1V3HMrPHoB3/Qx/Prn87klV1vcE2PqxJusJaVhrxnJk26nsDTy1FVonKYIGlosp+ptw3BUxHAU+Fn6+bvGP3zs5h04yDWPBd6UP3+YHyhmSEgmayseDI6pmDNc58zo2A4rqpyghlCzMaXo0M7rp2Swysv74qaWP794bdcPblf3PMl7oOdUl/NJFK45kUm1AokmpQ/kDXf/h//LdzDggtux5aVwQ2zhyCoAogaAZOX7r5uIEA7Szsqgh42//ApBUOns3zr82RlOLl9wC2s/usXuq2959kdWRkRH3Dl1PPw40u66V3oKUUSRD5440CUSeS9N/Zw6dXn4HBadFu15Ddjkcys/GJtVFphKWBGQatJO/x+Tdrh+0fMS7rJG08bVhWNj97eF9Wfj97ex2Xj+9TYzVMUsIly5KRiQ2/M5HCyYmyyApJFwhYsB18QTRMQBA1sVkorZF0AhYMznNbq8Gm7yD3vPxqV0CnXlsOSkQtY+cRWbrhtKC88tTVhVOOVE/rSoWNm0qCnZEiSgE0K8KPi5vdbntIfwFlDpvHyf18jv/d1vPSnHTHfC29iRYaOi6KAaAnwTdkhrCYzmqahaCpmyUym2UZ5eRXvrDyQdIN11qx+WKUAdOhIMKiBJUhQU1BRKfaUsqfoW0Z2GkaF14PLX8Z7hz/m+vPGY9ccqIpGsb8Eu+Jg7Yr/RAlNH0VIpiye+/3WmLEULBjFvZ88rOdo+eXZ1+L2lJFhteMP+jj2pyfJm3Q9lu4/obikSt/07No9i0uvPhtZNkU97NdOP59gQGXDS19GbDqeT2aOiaAawHTcxb7qVLvZw4bQ5ZZZBIRQ/pgS5QQBNYCmaYiixMY973BFr4t4slpDH9ylH1PPmMza52rGd/2tgxFMGqgCggRVAS9/fyRUVSzR5vSlM3ogBy3gNcXd9B45tTM2sxWp3B6Te+eycX3I65KJX/YiCSJSIKRQKLIfVVMRq9/TTYLWAIs//EPUPT64Sz9uOGNK1OokHKBV4fbF3exMVBAmfC/GozEbj8loydrBiTA2WZsaTeCox0KgwkumRaDCpyErEu2dlhhNoUKRQABF9cakZC3ylKDKCldP64tW7U+dSNMym00Jg54U2R8SwrUfuAgURcMta/z+46ei/Pef3PYPZgyYmMSlDSRiIwsn3ng+7333L1y+cq4/bxxPbXshQpO/hbE39GHjC7tiHupwuzhtPLV3DdNyrwVZoLiymOVbn9fbWHThXO77MHpC/N51iJsHXofVZGbVzg3ccf6tXH/bYAQBkDSe2/kS24/uYP6Q2+OO5Wjlj2RZnczufzMdrDn4JQkpR+DpL9ZyZeehBFwuCte8SI+ZN5Mh2vRNvQq3D9ks8W7he0yddQmVZQGqPAH+uX4XAJeN60Nu50xECTRRI+CB4x4Xn5d9ybiH7kNQFI56TvD7L5/E5S3nNyNuZf3uf4ZWTiNn8+y255kxYKIu3AEu7naBLtwBMh0WKsv9UWaUa2cMoFefPPbtKkx433Swtsev+WiX44jRRq+c2pv3Ct9nTMdL2Vgt/MMrRtkssfnd/ZxzcTYPfvpHXVt3kg1eWbe5KxH6bLy0w9uP7uCmAZOZUTAcRVEpOVGpC/dE2nBrMo1ECfM2apaJxBDwhITlkhXbY9IFP1zwM0iwhDRhiknJmmvLQdUUJJOAUO37m2iT0e8Pxtzg+pL4w+hKPE4pO76Qj/MAFnlKaGdx8I/d67jphmm8/sLXMcvReJGFa5/7DxdPvYCg7NcFc7i9P/37bxQMmc5F07rTLbMzaAJvvxZyywu7vP3fgY1sP/oVY3uPwWGxx7RR7q2I29fwiuGmntN46a81WuG1+efj8pYDsO6b18mfOpVNq/ZEfb7xyOvc3HM6G1fuoqz0a5zZGVx1wzn84pzLeffbfzHuzjlYKnzs+/0fkLOymDTpekRHOzSvB3tGkI373qFPVm82v3Qs6vd569VdTL99CCWlFVHXb+wNP+Wo5ubx7c9FjeWPW56mYMh0Luk2iu7mbtzcdypZNnvUMQ7ZQVnpd/rrEaPPjIkifWXlF0y9bTDHj7oT3jdlJ7y89LftoRXAzCEhG72mcrjiGCv2rWLCmVfpE3G43Vdf3sG4Kf0YPPo0/r7vH/q1f3TLkyy+8E5QYis0Qfy0w6F7XENVFCRJpEPHTK6ZOiCpNnwqmkZaC60vO04LEFTVuAU/gmripZsYkLlrxCxybTkANfbLoJn1z/2XDS9+yfjr+vPl9oOMv65/SMsFXaPKyrHF3ODxKvE8uuVJFNkftw/hBzCSXFsOHWzZzB16EzkdbMyYM4zZCy9k+uyh2LIF/KYqNC1+tKZDdpBptsUVxO1tOXTOaY8oiLz92i76D+7OjILhXDauDx+/s48heQPJteVQ7nMjIMS0Ue5zx+1rhd+D4Jd1QRruyysr/sPkXtcAsL/kACu+WcVF07oza/7PGDm1M25zMT/tNCxGmL3+wtd4KoKc3+Vcnjj0BnKXTvgKi6jYt5/vHryPb+bdybf33oPm85Fry2HdN69z5dTeUb/PhPwBFFWUxPRp4wu7yDF1iBlbltVJViCPzauOsXzpx2xedQyzx8HgLv30Y8IrqjCJNPSKQCUjp3Yms6PIpPyBMffNx2/v14998ZltaGhgDSJlqLi8ZdUTSZzc99kZ/H3/P9hfUpNipMhTgprEhSTsQRNzj4dNO4pKUFFRtOq/CUwdkXbzOQsuYnrBsHr7nhs0DEODp2EFPxRFwylls/jCO6Psl5pSEzr+7uu7GTH6TMxmiRmzhxMMBjFJpigvmqg2E2jkqqbGnYlru7DptTdtWbhKPbgojfqsYOh0XvzqVSb3vCaudugOuAnij6u1SUjglVEFjX27CnW/8jBDLuvKrCHTeHPfB0ztd01MGx8e+IS7fjaLR/8V25/83tfFFUpd7J30dlzeMqQMlcd2PI2rqowFF9yOVbTH9ejIkKyYLSL7S77nqDfWw8aSl0tJwM2sIdN4cts/WPHNKiZPu4Yu9o4UVp0gYKtE8MT3t0YRYsY2udc1vLIi2nVw3YovmPHLyXzvOkSRpyS055A/WT8u0YZuia+UZ3eu4s4Rt7HlyL8YObU3WWYn2RlZ/N8/vogKDNI3NX0mnBYnNw+8DqfVkcAcouHylkWNJ57HTCSJ7vGGBPWcaqaR1oIh4AldhMUzh1LoLsNqEfH6VPIcTkwkvxcVRQMl2n4pS5L+gB056GLNis9wZmdw0bTumDIgz9IezVO/JXGihzDRAygKYlSIOYQmiuVbQ7bh1bvXx5hvJuafz6oDq3H5ynXPjnieFYnsqTZLBq/sfo2Jfa5CEkwxbUzscxXZYo7eV0mQ8Ko+XFVlCfcLTKIUdbwoCswdclPNOEUxvkeH4qW9xcGfrvgdbm8lP/ntr/l+2Z9qIo4XzqPcaeXNrzYwY8BE2lkctLNmsnb3q+w8vod7LvoVhW5X/D6ZxJiJqou9Y9yJRtQkFo2aiyAIHHMXsvHw61w0bRhd7J0wy6ZYs8WNAzE7NRZfeCeyauHyMy/Uf1chICQMDAoqGjYyOc1hXkXglwAAIABJREFURhS0GBfNSfmDEEUhrjIQ/l3rc48bnDwYXjRE2L5r3fxO4tu+kxEvNeq1+efjkgt5Y9/73NR/Cpo3/ryarn7k5jr4sfyEHmIeyeKLfs3iD/5Ez5we3DWoAE0REEQQJfCLPlRNRZZMqKqGoikxWlvclLHVgknVNH35jiWIoikh4YwJMSDHjiEjwAHXQTrYsjF7HKxb8UVCn/1E1zrgDfLy32v6ctUN52DNFsgwWVE1FXegkld2vs4VnYeSLWfSzuZElTNRVC3kPYKKJIqICATUIBImTKqZStx4S7XoPYzqQieKokV5nshBKyv/8knMZDByamee3bmKB0b/L4qqxmjB9fHoCI1ViaovkOgaJWo3vIHfWG28OWgqL5rWSIsW/GhOWqyiUxx3sFxbSNvEG1/bToYkhQRGUFU4Wvkjq/etx+UtS0lYp+MhzM11UOQuiTumGQMm8uiWpxo9vnS4mkk2he/LDusbrYJfJtNkx5FhRzGFXA7rGn+H9pmUuapQNTXUF1kBvxQxITXsekqSAGYFISCFXEkFMW4uofD1qD3pXTm1NxsOb+TaPj9vkKKQaKwul6dVufg1FYaATw3DTTIF6mv7rrM9RUUhJCQ657Rn7tCbUhYu6VoSx7PPh23eqS7PE/ex8fZUSRIo87mjAsV+M2ImQcHH3Zv/nJIXEYAgCgSU6k6oQFAkMlCsoddTUTSoqmlLSTLQmOAbSUOVA+R3mJRWLVkQhXoHBhmc2hgCnvrbvvXv1aHJpkNY13cZLwCuUg8CAjlStM1bFiXuGlgQ0kgJaaR1Rc2ms3+RhPcIsqxObu47FYfswK7Z+ceuNfrvkGVth99VitUuowlyo7P2NSVRYw4CwdCjFf7N052B0MAgFQwBD8iqhTtH3MYfIiJC7xxxG7JqIUBiYRqvfFk63b9SOUekgEWFt17bVVN8On8QNodVFyQeT5A1K7bGtAUkFdKJbboNvwaKppJldZJ/Zti/PZRj5voZk5jcazwVfg+5QZUfHnqULyLSMVNdEjFyMjNJYqs0V4TNQwIgF5Wxu1ZqaS3PiarRIC1fNz2h1igiDWzLoO0iLV68eHFLdyJMVZWfptoRsNsteDzx/clV2c8HB7Ywrf8Eruh5ET87fTAff7+VM9qfBkEp7nckUeDFZ7bpG2s+b5Bv9xbRf3C3UGm0NFDXOcIC9sVntrH5nf3s3XWcK39xLn0GdOHIDy6+2HaILqdlIYkiZlmK29aAwafhjWxj53F69+mEbJFCNvDa54j4XCS6fx3yMul8mhObzYwkhYK9Em3xiLLG6bbTeeeFb6P69N3eE5x+Wh5vr95Hr96d8X39Ff7iEpRKD64vvqDTRaNQTbLep4/fju1zayC8Yf7Q5sc5O6MLxx/+s+6qGR6Lt///8OhnzzKwe18yxIw67/3wPRzZ9itfb2L7kS/pnXcma3e9zv/kdU+prdZOsue1rdGYsQqCgM2WuBasEegEIED/Ln1Y+vET/OrNxSz9+An6d+kTCplPQHOkHq3rHHEjUld+TjCgMPrK3mQ6LHqWv0Sl6FQ1fp1NvTRhnHOEP49sM1zUetO6nXFr2NZGCpjpYu8Ut096ErO1e8ibdL3+Wbj2ZbI+tRYig9acki1ueUenZKszmK2utqEmRcWFPYbXuy2Dto0h4KuJzBsSfmCSKUFhf/BI9PwaaaKucySaAMxmk17AOZzlL1FhYzEiL3tkG+FJJNkkE9lm/JqtiYWuomiYRClun8IFtMtKa9IzQ03ty8ZOruEi0orFpxehTjeRG/dliiduHc8yxQPUHVGarO0wRZ4SPQpZ1UIukTbNj13xYNP8TTJGg9aPIeABNYkXTSLC+TUiQ8nTnV+jrnMkmgDCQj27vZ0t738TEuSSwKQbB8a0JUjJJ5Fkk4wgoRdLThR6n0xuqWgx47t6cj+2vP+N/lrzhoRgZO3LRH0SxbqFWGQR6blv3sPiD/9AGaVpF4CRaSReOvAOZ86/Sxfylrxcut45h5cOvAOktqGfqO0w4bQPubYcZNGE7Cpi96JFfHFbAbsXLUJ2FRlC/hQkJT/40aNHYzabsVgsANx1112MHDky6pj58+fz73//m+zsbAAuv/xyfvnLX9arMyebH3xzpB5Ndo54m5yRqVvHTjqPjWu+YlL+IFRHFS9+tYGLu11AltmJM8OBSZJQFJJulCbbSAVQAiquEg85Hey88FT9amXWHh/A27U2iZ02Dfy+KM+TeH3SA5yUzOSbjGmOeUg8ruigtbG9LmFct59R5a3EYsngmb0b2H70q3oFs4Xv4XgBceE0ERP7XEVHxcbXCxfFpGc4e8mSUKm5kwDDDz410hLoNHr0aJ588kl69eqV8Jj58+fTt29fbrjhhgZ1FNpGJGtzEw6qCqdu/fjt/XrqVptdRtU0NHOQez5YllCo1TVR1TXJCIAoCHgqA43yKqqXS2iGyuHiQjIkK+6Am3XfvI7LW1anoI4sIh3J41c8gOizpNTPVKkdZCWrFgKiD0EIjS0UZ5F68FXkPVzbi0YgVJJRCpix+iv54raCmO8PeGo5lZItrWNsKgwBnxpGoFMKpDOpUnNTE1RVk7rVbJHwBxT8wVA0jKIGkgZy1RW4lOzzyM8aWmknlfPUxq8GePDTP8a8X1dwWkNjHhpC7TiIkMutrJvYGhMfUbvtcAsKGppoiptgTRONx/1UI+W7+q677mLs2LEsXryY8vLyuMc899xzjB07loKCAr799tu0dbI5kCQBp6KQrQRxKspJZ6+MTN2a6bBGa+AJbLbpFmqppo9NBw0dU10pcNsCPpOFsxbMi7L5h/cvDE4tUjLRHDt2jM6dO+P3+1myZAmVlZU8+uijUcccP36c3NxcRFFkw4YNPPbYY7z77rtIUnw/8taEqgYJHD/I8XXLCJYVYXLm0nHCb5E7dkdsA1qPqqkcKjvKss1/1U1Qvx35S05zdqm3kNdUlUBZGWogiCibkJ1OBLH59+obMyZVUyn3VhBQg8ii6f+3d+7xUVXn3v/uveaWSSZXkgiILYdKi3pED1ZUpCqttVYrPaXeEG+vFguCftTUgLSFohEvaOVSEDx8tFiqyAGhcLS1fdFWqRZf1Go5gPdKVZIQkphkMre99/vHZHZmMpdMMtcM6/sPZG5r7dtvPet5nvUsSh0lGbHgc0m+XCdJbhlwsbEDBw4wa9Ysdu7cmfBzEydOZMuWLYwcOTLp386VD77M6uHQb35GoL13Smspq+aYGXfT7ndkpD+ZJNaxpqOImRAK1rbmiM2tvzq/Hn/P6tJsI4SCWqTj9fuGlFttsEi/dGGSSR98v0O62+2moyPYuGEYPPfcc4wbNy7qc42Njeb/X375ZVRVpba2djB9zj6GFiHuAIH2ZhSjcCo6aZoR3HvTawdPjNK9SWAPeE1xh+BinQNL7sce8PbzzcygaQblRaUpHZNEUsj0639oaWlh7ty5aJqGruuMGTOGhQsXAjB16lTWrl1LbW0t9fX1tLS0oCgKJSUlrF69GotliLg3FIGlrDrKgjeU/HcvZRNFD8RckanoARCF48OWSAqFfhV41KhRbN26NeZ727ZtM///xBNPpK1T2aZbcVI77c4oH3y34oQ4xcaORuJlZ6iqSrHmNnPVAVk5USLJA4aIiZ1ZfD4dnLUcM+NuFEPDUATdijP4usQklJ0R7oP/2rw7+fC/1tH6t9dNn7xqtbJv8T0Rfnpy5KeXSI5mpMD34PPp+AgPqEpx74umGVAeXBGp6AFUVTXFHXp98v9204+i/PRDaRWlRFIoyLwpyYDQNAO3YqNLONF13RT3EN6mZoTDEfWaogey2U2JRIIUeBNZfW/ghHzy4dhrqtE8nqjX5CpKiST7SIGnN79bVt8bGPFWTNpra+UqSokkDxjwQqdMkquFTk7Dx74FQ7v6XjjZXCQSa69RyF4WjVwQU5jIY00OWWwsCWR+9+AJ+eTN8xTa/zXGaxKJJLtIFw3xfcnSbyyRSIYyUuCR1fckEklhIk1UABTcpVUc/4tFWDAIoOC2ObEGt1HIdeckEolkUEiBBxBgaT9E+/88bJYqKL7odqgc2e/GExKJRJKvSBcNUGR46OoRdwhWkuz6n4cpMjz9fFMikUjyF2nBA6oRiFkuWE2xXHA2NuWWSCSSeEiBBxRFjVkuWFEGv9BJCBWvO5DSJtRDETmoSST5g3TRALqiUH3RbCxlwSwaS1k11RfNRg8TeCEUXBYfpcKNy9J/KQMFTHEHaG/t5pkn/h+FvDY2NKitX/UaK5e8yPpVr+F1BxBC3mYSSS6QFjxgGAodH7xJ8VU/Q1MFQtfo2PMnXBXB7QaFUHBqbWjtjahWB7rfg7OsFrcoj7tC09AxxT1Ee2s3RgEbs/EGtWtmn5HbjkkkSVCIs08p8IBfOHD/x7k8+MoqcwPnn0yaiUM4wK/jFH6ML9po+f1jZpZN9cVzcFYU06HFPoWKCmUVRREiX1ZRhKJSsJk5R+OgJikMCtWlKufOgBcvD+5aS7P7CADN7iM8uGstXoJ7jQrDT/OOlRFZNs07ViIMf9zfNIDLrjuNsooiAPOGKeSs+tCgFo45qEkkeUyhulSlBQ/o6Ka4h2h2H0FHRwUMQ4+ZZWMkME01TcfutHDN7DMKasqXiNCg1tcKKuRBrRAQQkGz+tAMHaGoCL/tqNt9q1Bnn0kJ/JQpU7DZbNjtwaX7dXV1TJ48OeIz3d3dzJ8/n7179yKEoL6+nvPOOy/9Pc4AKoJqZ2WEyFc7K1EJbrqtK9aYWTa6Yk34uxFiXqBumXBCg9q1s89E1w1UVUER5EwssiVcQig4FS+KEcBQLLiNobMHrRAK7bSy9KVHTfdk3aQfUyYqhswxpINCdakmbcEvX76csWPHxn1/3bp1FBcX88c//pGPP/6Yq666ihdeeIHi4uK0dDSTCN1G3VkzWfrXtb03+VkzEboNDR23bqfmip+itfUGWUV5LW7djixlEE23259zX2a2hEsIBae3mabN95vxmZpp9bjtifegzRerWbP6zHMEwZnr0l2PsujcO0BLbMAUEoU6+0ybi+b555/nvvvuA+DLX/4yJ510En/5y1+48MIL09VExigyPHh3Ps3PTv0+RpELpbsDY+fTFJ1/I530lLwN+COCrDU/rAdZSTiKfMmkyZZwORWvKe4QdN01bb6fmqsa6Ihzg+ST1awZcdyThn5UBegK1aWatMDX1dVhGAYTJkzg9ttvp7S0NOL9zz77jJEjR5p/Dx8+nEOHDqWvpxlENQJ0v7sb3t0d8Xrlt64Heh7i/+7zEP934of4aCVffJnZEi4lzipoxQgQzwIY6OATcgH525txWdS0uoCEosZ2Tx6FkfFCdKkmJfAbNmxg+PDh+Hw+GhoaWLx4MUuXLk17ZxLtTJIOqqtdMV8PdAZi+tiF1Up1hQt/e3PMh1ioetzfzDW56ldnhyemL9NmF5S4MuOui3Wsbd1GTOGyW22Ul6bv3MS9d2w2qktit9Pc1RJz8EGNPhbD0PE1fULjpvvM2WPtpfOw1RyHkgYR1g2dOyfP4oGXV5uziTsnz6KqpBzVlfzv67pBe5cXf0DHalEpK7ajqqnloOTrs5UJMnWsSQn88OHDAbDZbEyfPp1Zs2ZFfWbEiBF8+umnVFZWAvD5558zceLEAXUmV1v2CWGlZlp9lB/1C58VrbkDl0Wl6PivUzr+PFRHCbqnky/+/iKartKWR9uKhSw9oepoenotveT7oMb0Zfr8Wka2YIt3XYVQqZv0Y5buinSD6N0qzZ3p60d/905MHErMwQedqGNxWXw09Yg7BA2Lxk33BWePgd4ZQiqBXpcoZ9G5dwRnNz3xgJbDXQM4Byqtbj/3PrGbptZuaiqKuOu606lwWgft4pBb9iVHf1v29bsnq9vtRtM0XC4XhmHwyCOP8P777/OrX/0q4nMrVqygsbGRe+65h48//pjp06fzwgsvUFKSvFWeK4EHsNlUbIbH3EfUpzjw+YI3p8OhYus8ROPmB3utqGk/wVdyDB5PfvjoBhvsy0xfsrciMPHAHQxkhgtXPmTRmD74PoNPGdE++FLh5tPVs6N+Y+SsVXyhOXvbz+G1N4TK/FW7aAqbtdVUFLFk9iQUKfD9ktM9WVtaWpg7dy6apqHrOmPGjGHhwoUATJ06lbVr11JbW8sNN9zAvHnzOP/881FVlcWLFw9I3HOJECotHX4anthjWiALrjud8h4LxK53c6hH3KHHitr8IMdcfQ8esrfrUyIhGUywL1Pkiy9T0wzQrKbPXctQToSmGT3nOHSeE7ejaQZloiLKao4lxoZiiekCMpTeRzfX117TjQhxB2hq7UbTDbnQJsf0e/5HjRrF1q1bY763bds28/9Op5Ply5enr2dZREPhqRf2M2vqv1PqtPKF289TL+xn5vdPBoKbcscMpOkByJLA92elDSbYJ8kdyQ4+bsMe0wXkNnpTdHN97YWqUFNRFGXBC1WRG67nGDnAEnQjXDp5DM9vfNv0G196+clB94IW/EAsKyqba/D7s9KSsfQkQw9NM/A6a6ie0YBqaOiKwKs40Hy9s6RcX3sLcNd1p0f54C0UTDLKkOXoy4WKgdAxxR2CaX3Pb3wbEXqGVAvVF8+JLCd88RxQsyeeia20XksvvI+9lp5kqCKEyuEOP3NW7uGH97zKnJV7ONzhjyjBnOtrr2k6FU4rS2ZPYu38b7Jk9qSUAqxDDSFULEJFKD3/5lF5bGneAYZhxM7d7ok/a4pAKS6j6js/MleyKsVlaIrISv+EUPEqxZTNeATD3Yrntd/i++y9CCtN0wzc9mpqrmrIaRaNJL0EwLSMIejbvveJ3cEAZs9nwq99rsolaJqOQo+gaMZRY7nnexVKKfCAoipx6lAooIPbL3AWleIXVWaNFWHz4/YJMl2qIHQDPRl2A116xRyK3thAxeTLInyxoWBfdbWrJ31TivtQJ9kA5kADvfHIlxIKQ4V8WbkdDynwgKbAhZefHOGDv/Dyk9F6TCSrVdDaFuCZJ14NG6UnUFIm0LRARvsW6wba9PQBrr/5ZtxGZCGvUHpiW6sbi1ALYqn10U42A5j5VEJhqJAvK7fjIQUe0HXY9PIHXDD1BDOLZtPLH/Cj75+MAmh+g2ee2NNnlN7DtbPPzHjf4t1AAU1BC7uLsjVVlBZedslmAFOz+tj01g6uPfVSSmxOOn1uNu3dwfWnXJ7XhcfScU8KoRIgOGMSqhI8v0k8N/lehVIKPIBicPHkMSzf+Kb5EN1y+anBELTWsww7hshmalFWRNeSvIGyMVWUFl72CQ9goihgGKb4DFaU4qLAhWPP49HdT5rX98enXx1sNk3Hk27ScU+mshI336tQ5k+4N5cYCnv2HWLhjWfyaP0UFt54Jnv2HYKea6v2+OjDKasoSrnWRlJdI7mdobIxVdSsPnP1JfQWydKsvvQ1chQhhAIOP5rdCw5/3I3cNU1H0XRqKpwomm6Ke6vbz/xVu5i55P8yf9UuWt3+lDM4QuIOwev76O4n80asYpGOezJeIDsZ52t4Fco588/jmtln5E2AFaQFD4DdqvC9b4ym1OhGMTQMRfC9b4zGJhR8GlhtKpdeN4FNPW6asooiLr1uAlabir87s/OwZMuYZmOqOBRKyw4VF1Kqlmcy2TUDRc/A9U37LKMP6bgnU12Jmy8rt2MhBR5QVAOXp5VAe5OZBukqq8FnrQJA1wyKi61cM+sMDCM4U1bV4OvZIJkbSBUKl103wYwVhALBqlD6vemEULAHvGYdHq8ldopdNkrLpiLQQ8mFlGq9+kyUB1CJc30HKe+ZKEIW1UYa7slCXombL4ZXTnHoHoyudlp+/xif/+bntPz+MYyudhy6Bwhmqjz/7F4aP+ugo91D42cdPP/s3rwSDV0z+PML73LB1BO5dvaZXDD1RP78wrv9DkJCKFjbmtm3YAFv3jSbfQsWYG1rjukuEH4bdZN+HKx8CKaACn9qy+FDrgrd4cVn7ebxtzZyy/M/Y9FLD9FOa1zXRV+GkgspkeWZDCFRCscUpUGS7uubiusjWdLR51AgO3Q+wwPZmUQIFUOoNLW6MTK0QEpa8ICiBWjesTKiDEDzjpUMn7EYsKLrBu/ubeLdvU0R3/v2Jfkj8IZOnD6emPB79oCXfUvux9sUPHZvUzMHltzPuIYG3ErkQzKQIlnJEsvq/vHpV9Pu7eC9lo+StmqFUPHF2zw9j1xIIVK1PPtm15xxYi1zL/oKFl9nwllYItJ9fbNRhCwdfQ4PZGfKldSXbMxuQAp8EENHFJdTdf71Zr33tr8+SyhCme+pUDD4Pip6wBT3EN6mnkJqItoKSneFxliuikd3P8m1p17K0l1rkhLo0MPS5nEPmd2JQpZn35LBwm9L6pyGi5ICONqaOPDTn+JtasZeU81X59dD+cDLBafz+mbL9ZGOPmd7JW4mYiixkAIPYLFRed4M04o3a81YbBAYfCpUNgN+g+2joVqw11RHiLy9phojS3V2Qq6K46tGM/Vr3zbzr6ucFRxfNZppJ3wXQzGCWSZxzl/oYalw2blp2g2seXNdQtFMNuaQSdJleSqA0/AlPQvLJkOpCFmmg8F9yVaJZSnwALoe20Vz9T3A4DbkzXbAL7yPqqKgG0ZSK1m9FjtfnV/PgR6BCFl/Xos9KwEmoaicNuLkqPzr+sk3M2P8D1j52uP9nr/Qw9LU2s36zXD1BT/CVWyhurwYi9/aZ7VvT8yhz/EOxtpNlXRZywOdhWWLXLg+BkO23CURbWZpdpN/c9dcoGsxKzUGawUHESoUBdwU+TsoCrjpLx6Si4CfpukENJ2yCieBnnzp/r9j4C+vZlxDA6euWcW4hgb8GRK7WFX3hN/GNaf8MCr/+rD7iCnuAOWOMjo6PGAQVbEvPOB44JM2Gh77Ow//+n8hhkVsD3jNwQx6rV17wJv2480WoVlYONmchSUilMNvMQwzhz/fyEYwuC/ZCuzm/g7IB9TE9d5tVhXR0sg/7nvAtPq+Nu9ObFW1+Pyxb9ihkDMeQtOM4FQ+ZO1lSNzjlVJQUKLOlcNiM187vnI0133lKp57cj/trQcivgsDcwXkq7WbCrmehQ11crEjVaIVyukk37QmZ1RfNDuy3vtFvftg2n1u9veIOwQFYf99D2D3ueP+XihLIqKNPA34ZYN4pRQUevOvw/EEfOZr075yMc9t2B/zuzCweuT5bO3GI5RG2tzVEnPFazZnYYVIJlJOkyHWCuV0c3SqTQy6mw9Scu3dlMxdTcm1d9PdfNB8z9C0mFafocUPFWUqZzwRQig4DR+epmachi/p/PFskKiUQqxzVVM8zHzNZXUlLMMQDGZ70S3dWOw+LBhxH5aQtRsS+QhrNw8JxXIWvfQQN+/4ady1AaFZWJdw4lbyc/VuvpKquyT03BVr7rx77hQjtKtFEqxcuZIVK1awfft2xo4dG/HevHnz+Otf/0pFRQUA3/nOd5g1a9aAOtPS0pmxAl6Jdi4vcykc9nxBx5HDOBUbbsOHq3IYwxyltHcYuPDyj7t+GpVpctK999CRYE/WUBZNunLGExEKHvadpodbcqFywskGitOJRaisX/Ua7a3djP/6sZx17phgXX2LiiKC/eh7riAYy7AEbKz/1d+iUkCvmX0GZRVF/LP106h0wzLiB7MznUWT1uwph59FLz0Ulfq56Nw7wJO/FR5TJdHzmgkGm0WTzHPXH6kcq6oqVFWVxH0/6Xnp3r17eeuttxgxYkTcz8ycOZMZM2YMrId5QLfmRzS20rF0FYd7LlJ53Vy6jy0CLCBUjr9lDu8tX2lexONvmROMvCbI90p3zngiHJqX/40RPDzh3ga6sOV855lQGuc7b/yLk04dyW//a3dESQWny4bmiXGuNCuGUOKmgH7h6YwZzE60OCqTMYd0Z08NpVjOUGawefADWSiYC5K6R3w+H4sXL2bhwoUoSv5MP9KFpTvAwaUrIi7SwaUrsHQH4+iG18fH63/D6Buu56SGxYy+4Xo+Xv8bDG/ijBibQwWnH83hAac/+Hem0P0x3UjowWNI5APPBqE0ztPPHs2mX0fX1jcSDpTxK/b5dX9KS/7TTbqzp2QsJ79JGLTPA5Ky4JctW8Yll1zCqFGjEn7u8ccfZ+PGjYwaNYo77riDMWPGpKWTmUaJ42NXND04BFoE/rY29i95wHzfXlMNlvh7stocKi3+Fh7qWY1Z7azkjkk3UeWowudJv/gYljgLliwC9PSUE07VtaFpQd/QYGrrxyu4ZlWtebV6NZ0WtxAKTl3hJ5Nu4sGw+2ggK16TakPx5mwv16FOrhcK9ke/vXjzzTd55513qKurS/i52267jerqalRVZevWrdx444386U9/QojkN6ZO5EtKB9XVrpive1q8MS+SahFUV7lo79L5av1POHD/g71+tvqf4HPaqC6O/ZvNXUdMcYfgQ/7QrjUsmnIH1dWVMb+TCq1dGqPq5pozEXtNNaPq5uJzWKgudtHZ4YlZysBmF5S4ivv9fUPXcf/zE/bde5/5++PumofzS8ehqMlLV8jF0rcfQqhUVvTfj77ohs6dk2fxwMurTQG8c/IsqkrKUV3ZF/m2biPmgGO32igvjX2vxMIwdHxNn9D42/sQxeX8/NwrUKqGY7M6KHW40jKAmW1sus9cwV176TxsNceh5MEMId7zmk8Yus64u+ZFPxfDKigewHORqWPtN8i6du1a1q9fj80W9CcdOnSIqqoqlixZwtlnnx33exMnTmTLli2MHDky6c7kKsjqEn78LUfwt7cjHA40jwdrWRnWqko6NCtWm4qXLhzdfiy6QkA18BRZsVOM3xcnD97h4Zbnfh71+vLvLkZ4HGk9NgDd4WX5a+u4cvT5lAkn7Zqbpz76I7eccQOqx56yD95p+Ni3YEHUIDhQX6PNJnB3+KLKGjtdNny+gS9gr652ceRIZ9aC2f0p+YNfAAAM9ElEQVRh+uAHEPSNhcvio2nDgqi1GTVXNdARSI9vNxttDJZsB1lTIdWZbU6DrDNnzmTmzJnm31OmTOHRRx+NyqJpbGyktrYWgJdffhlVVc2/856Ahu718uGax3qDqLfOhYAGihW/T8duK8ZX4qXb0BCKwK7Z44o7gFBjVwsUAxjVB4KKSpvnCxbveSyivVAt78GUWwgnXQuEfD4Np8vGtbPPRNcNVFVBEQxK3EMMJJidaZdERI0ZdKyKglMzQPfiFsm3pRiBmKurFSMApEd8s9HG0UA2FgoOlpQcRVOnTmXt2rXU1tZSX19PS0sLiqJQUlLC6tWrsVjyww+VDO8tiwyyvrdsBSc13G2+HxRzK4JgZoafxMJoU63M/8YcjrR1UiQcdGseKstLsKlWMlGsQPht3DV5Dp1Hms1Uz5LK6ghfbSo7z6iqir2mGmt5OcdO+08sJSVoHg+q1Uo/pyKKcDHXtIH3ZbAIoeD0NtO0+X7TJVEzrR63Pb2LgjTNQGDD1dNW2yDaMhRLzNXVhpK+ZyobbUhyy4Dy4DNNrlw0JZqbN26aHfX6f6xdRafqHFR7NpuKu9PPM4+HuSKun4CzxIovgeU/WIRQsHe14W1sNN1M9tpavMXlaRGvErz4j7Ri+LwR6aJfm1+PL4erJgcyvc2mSyLVtmINRrWXzqPLOixt5zpbA95gGEoumlTJizz4Qka3iphBVr0nA2UwGJpiijv0pAM+vodrZ5+Zji5H4TD8aB5PxGu6x4PD6acrDZdZNxQMv88Ud+gp2ZBCzm+290/Npksi1bY0zcBtDw4IIXeSrbyCLw53pa2PsdqQWTSFhRR4wOsQfOVn8/AccaM4ijE8XTgqnXgdAuKXm0mIrhuDSgccLCo6fo8nMo5wyxysaVpcFbA5sFVWpq1QVy72T82mSyIdbWmaQQc2QgOCIwOZLX3bYAD3Sz7U1ZckJve5UHmAXbXhUcvZuONz1jz2Dht3fI5HLceuDt6qU1WFsj4FjMoqilAzVcAooEVZ1+8tXwla6gsuhFA4oh+hMdCetkJdqS4ICpUebmt1YxEqNpuKy+KjVLhxWWLXA3Ebdmqm1UcUlauZVo/bGFgdGiGUrLWVrwxkL19J7pAWPKB5DDY+EelO2fjEHq6/eaL5GZtNYGgknfmhCJh6xXi2Pf130wc/9YrxKIKMBBUNQ49dEE3XIfmlCDEJbatX7ihlzh1z+PShXh/8YMvSaoZOuaOMG066CpfVRYe/g83v74haEBSqn6MqCoYRPP/CquDu8EeXLtDa8b79PJavnodacSxWYUEPKzymaQZeZw3lVy1F1wxUoeBVFbQBxESS9VsXuvsj35foS4JIgQc0XaHEZeeCqSdS5LTS7faza+f76LoCGIPK3dY0g2KXne9OOwmbzYLPF6DYlZ4HvG/RMFWAotkZ84u7URzF6B3tND3zW/xtbSgi8SVOpgBZaHVms/sI20rf5AcNDQgsWCwCXfQvkLHaEKqV/3P81by+8yCnfL2SYSXHcNsps7AKzCyjUO7+n184wMTJ/8bvNgYHyytv/DrPbf5HVNmF7047ieJTpvPiH9/j3b1/icr1F0LF3ZFaPR6n4jXFHUAtLqeroxvVGiyoFn7+UnF/5DuFWFe/ECkYgU+lUqKwqEy9cnzwS4pCcYmNqVeOR7Wo4NMxNExxh976KYkCppqmI6wqw2pL0lq9MdaCpSt/dBpuv8IzOz43X5t241zKhKdnM4HkfyuW4IXqoZQ7yvhmzRSeWvtW0gIZr40ixcrrOw9GCHff3wvVz7lg6onmZwBsNkvM+IbNZmHTr9/ggqkn8u7eJlP4r5l9BhC/Hk/o/WQID57aRhyPOnkOv3n6AO2tH2a9gFsuyfcl+pIgBeGDD4nI+lWvsXLJi6xf9RpedyBiW7eE31cVfF6NDY/tZtX9L7Hhsd34vJpZ8H+wAdPQFnqaoSe9hV5/xBKp9iOeqAFo86b9dPshUZPJFiAL1Wu/fOx/Jtx4YyBt6JrBKV8/LkK4+/5eqH5OkdMacf673f6Y8Y1ut9/8fIjwejvpqMcTCp4COM6YzqanD+SsgFsuGWp19Y9WCkLgU62U6PfrURUON/16D/6e7fiyHjBNQCyRimfRWquqEz5wyQqephmUUcGxJcMHLJDx2lBVBWeJLeHvKWqvcIef/10732fqFePN18oqirjk8vHs2vm++fkQZRVFoZ0Xzd8LJ/z9ZIgInjrKUh4whipyF6mhQUEIfKqWWX8WuiLgsusmRAjKZddNCAZMs0wskfL5ArGFy2JJ+MANRPA0zUBRYg90iQQybhsCSlz2hL8XqiH/1uufcMnlvYLe2eGl2GXn2pvPZM688/jutJPY+dx+Oju8XHbdBN56/RPzt0J148N/L/I6njYgz3h48NRWVpnygDGUkbtI5T8FsZI1fLegEKEdfwI9PopEq8WsFsGvf/Vq1PevvflM/IFgEHWgWTSZIp4Pvsvj4XdP/mNAwcOBFiAbTMGyRN8RInY2TPjvxcqiCY9nDKsqoa3NHRZwVtA1I27cI527WmV7ExW5urMwyeRK1oIQ+GQetISlCpxW2lo9UVky5RUOOsOm+/lCrCwaTQRQ/AJDB5vVgi+gJbnl2MAEbzACmeg7qQpuroUgm9sg5vpYs4k81uQ4KkoVpFopsdPtp7zCEVHh0G5X81LcIUbRMA2C3rbg4FhS6kj6hhloAbLBFCxL9J1UCqDlA0O9/5LCpiAEHlJ/0MLFXNPA75ZPq0QiGdocJeEgiUQiOfqQAi+RSCQFihR4iUQiKVCkwEskEkmBIgVeIpFIChQp8BKJRFKg5FWaZKZru+SidkyukMdamMhjLUwGe6z9fS+vVrJKJBKJJH1IF41EIpEUKFLgJRKJpECRAi+RSCQFihR4iUQiKVCkwEskEkmBIgVeIpFIChQp8BKJRFKgSIGXSCSSAkUKvEQikRQoeVWqIJOsXLmSFStWsH37dsaOHZvr7mSEKVOmYLPZsNvtANTV1TF58uQc9yozeL1e7r33Xl599VXsdjunnHIKd999d667lXb+9a9/cfPNN5t/d3R00NnZye7du3PYq8zx4osvsmzZMgzDQNd15s6dy7e//e1cdysjvPTSSyxbtoxAIEBZWRlLlixh1KhRaW3jqBD4vXv38tZbbzFixIhcdyXjLF++vGAHsHAefPBB7HY7f/jDH1AUhcOHD+e6Sxnh2GOPZdu2bebfDQ0NaFphbidpGAZ33nknGzZsYOzYsezfv58rr7ySb33rW6hqYTkb2tvbqa+v5+mnn2b06NFs27aNRYsWsW7durS2U1hnLQY+n4/FixezcOFCFOXoKV5UyHR1dbF161ZuvfVW85oOGzYsx73KPD6fj+3btzNt2rRcdyVjqKpKR0dww/iOjg5qamoKTtwB/vnPfzJs2DBGjx4NwDnnnMMrr7zCkSNH0tpOwVvwy5Yt45JLLkn71CdfqaurwzAMJkyYwO23305paWmuu5R2Dh48SHl5OStXruRvf/sbxcXF3HrrrZx22mm57lpG2blzJ7W1tZx44om57kpGUBSFRx55hNmzZ+N0Ounq6mLNmjW57lZGGD16NIcPH+btt9/m5JNPZvv27QB8/vnnVFZWpq2dwhsaw3jzzTd55513mD59eq67khU2bNjA7373OzZv3oxhGCxevDjXXcoIgUCAgwcPcsIJJ7Blyxbq6uqYO3cunZ2due5aRtm8eXNBW++BQIA1a9awatUqXnzxRVavXs1tt91GV1dXrruWdlwuF7/85S9ZsmQJP/jBD2hpaaG0tBSLJb02d0EL/Ouvv86HH37IN7/5TaZMmcKhQ4e44YYbeOWVV3LdtYwwfPhwAGw2G9OnT+eNN97IcY8yw4gRI7BYLFx88cUAjB8/noqKCj766KMc9yxzNDY28vrrr/O9730v113JGPv27aOpqYkJEyYAMGHCBIqKivjggw9y3LPMcNZZZ/HUU0+xZcsWZsyYgcfjSbunoaAFfubMmbzyyivs3LmTnTt3cswxx7Bu3TrOPvvsXHct7bjdbtN3aRgGzz33HOPGjctxrzJDZWUlEydOZNeuXQB89NFHtLS08KUvfSnHPcsczz77LOeccw4VFRW57krGOOaYYzh06BAffvghAB988AGHDx/muOOOy3HPMkNzczMAuq7z8MMPc8UVV+B0OtPaRsH74I8WWlpamDt3Lpqmoes6Y8aMYeHChbnuVsb4xS9+wV133cX999+PxWLhgQceKMh4Q4hnn32WBQsW5LobGaW6uppFixZFBM+XLFlCeXl5jnuWGR555BHeeOMN/H4/kyZNoq6uLu1tyB2dJBKJpEApaBeNRCKRHM1IgZdIJJICRQq8RCKRFChS4CUSiaRAkQIvkUgkBYoUeIlEIilQpMBLJBJJgSIFXiKRSAqU/w/H8nXbxhRTdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#END table of all model\n",
    "n_splits = 5\n",
    "thre = 7\n",
    "random_state = 20\n",
    "data_new_2['number'] = data_new_2['chembl_id'].rank(method='min')\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_new_2['number']= lab_enc.fit_transform(data_new_2['number'])\n",
    "#category_new is column where have convert category(inactive/active) to (0,1)\n",
    "data_new_2['category_new'] = np.where(data_new_2['pec50']>=thre, 1, 0)\n",
    "\n",
    "kf = KFold(n_splits = n_splits)\n",
    "a = -1   \n",
    "       \n",
    "for trains, tests in kf.split(data_new_2):\n",
    "    a = a+1\n",
    "    #print('Number of split:', a)\n",
    "    train = data_new_2.iloc[trains]\n",
    "    test = data_new_2.iloc[tests]\n",
    "    #clasification, i used bin and category new columns   \n",
    "    case = 1\n",
    "    x_train = np.asarray([x for x in train['bin']])\n",
    "    x_test = np.asarray([x for x in test['bin']]) \n",
    "    y_train = np.asarray([y for y in train['category_new']])\n",
    "    y_test = np.asarray([y for y in test['category_new']])\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    rfc.fit(x_train,y_train)\n",
    "    rfc_predict = rfc.predict(x_test)\n",
    "    conf_matrix = confusion_matrix(rfc.predict(x_test), y_test)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    accur = metrics.accuracy_score(y_test, rfc.predict(x_test))\n",
    "    #print(accur)\n",
    "    \n",
    "    # Sensitivity\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity \n",
    "    TNR = TN/(TN+FP)\n",
    "    #MCC\n",
    "    MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    \n",
    "    try:\n",
    "        pomoc = {'Case':[case],'threshold': [thre],'Split':[a],'Accuracy':[accur], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC]}\n",
    "        df_table = pd.DataFrame(data=pomoc)\n",
    "\n",
    "        data_out_end = data_out_end.append(df_table, ignore_index = True)\n",
    "        data_out_end.drop_duplicates(keep='first', inplace=True)\n",
    "    except:\n",
    "        pomoc = {'Case':[],'threshold': [],'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[]}\n",
    "        data_out_end = pd.DataFrame(data=pomoc)\n",
    "\n",
    "        \n",
    "\n",
    "    #regresion i used bin and pec50\n",
    "    case = 2.1\n",
    "    x_train_reg = [f for f in train['bin']]\n",
    "    x_test_reg = [f for f in test['bin']]\n",
    "    y_train_reg = [a for a in train['pec50']]\n",
    "    y_test_reg = [a for a in test['pec50']]\n",
    "    data_new_reg = [i for i in data_new_2['bin']]\n",
    "    rfr = RandomForestRegressor(n_estimators=101,max_depth=4, random_state=random_state)\n",
    "    rfr.fit(x_train_reg, y_train_reg)\n",
    "    y_pred = rfr.predict(x_test_reg)\n",
    "    sns.scatterplot(x=y_test_reg, y=y_pred)\n",
    "\n",
    "    y_pred = rfr.predict(data_new_reg)\n",
    "    data_new_2['pec50_new'] = y_pred\n",
    "    \n",
    "    \n",
    "   # print(\"Regr\", mean_squared_error(rfr.predict(x_test_reg), y_test_reg))\n",
    " \n",
    "    #??? i don*t know as i count acur, sestivity, specifity    \n",
    "    #?? Good to frame spe, mcc, sen = 1 when accur = 1\n",
    "   \n",
    "    \n",
    "    \n",
    "    #classification after regresion i used bin and category_new_reg\n",
    "    case = 2.2\n",
    "    data_new_2['category_new_reg'] = np.where(data_new_2['pec50_new']>=thre, 1, 0)\n",
    "    train = data_new_2.iloc[trains]\n",
    "    test = data_new_2.iloc[tests]\n",
    "    \n",
    "    x_train_cl = np.asarray([x for x in train['bin']])\n",
    "    x_test_cl = np.asarray([x for x in test['bin']]) \n",
    "    y_train_cl = np.asarray([y for y in train['category_new_reg']])\n",
    "    y_test_cl = np.asarray([y for y in test['category_new_reg']])\n",
    "    \n",
    "    rfc_reg = RandomForestClassifier(n_estimators=101, max_depth=4, random_state=random_state)\n",
    "    rfc_reg.fit(x_train_cl,y_train_cl)\n",
    "    rfc_reg_predict = rfc_reg.predict(x_test_cl)\n",
    "    conf_matrix = confusion_matrix(rfc_reg.predict(x_test_cl), y_test_cl)\n",
    "    #print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    accur = metrics.accuracy_score(y_test_cl, rfc_reg.predict(x_test_cl))\n",
    "   # print(accur)\n",
    "    if(accur == 1):\n",
    "        TPR = 1\n",
    "        TNR = 1\n",
    "        MCC = 1\n",
    "    else:\n",
    "        TN, FP, FN, TP = conf_matrix.ravel()\n",
    "        # Sensitivity\n",
    "        TPR = TP/(TP+FN)\n",
    "        # Specificity \n",
    "        TNR = TN/(TN+FP)\n",
    "        #MCC\n",
    "        MCC = ((TP*TN)-(FP*FN))/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**(1/2)\n",
    "    \n",
    "    try:\n",
    "        pomoc = {'Case':[case],'threshold': [thre],'Split':[a],'Accuracy':[accur], 'Sensitiv.':[TPR], 'Specif.':[TNR], 'MCC':[MCC]}\n",
    "        df_table = pd.DataFrame(data=pomoc)\n",
    "\n",
    "        data_out_end = data_out_end.append(df_table, ignore_index = True)\n",
    "        data_out_end.drop_duplicates(keep='first', inplace=True)\n",
    "    except:\n",
    "        pomoc = {'Case':[],'threshold': [],'Split':[],'Accuracy':[], 'Sensitiv.':[], 'Specif.':[], 'MCC':[]}\n",
    "        data_out_end = pd.DataFrame(data=pomoc)\n",
    "    \n",
    "    data_out_end = data_out_end.sort_values(by=['Case', 'threshold', 'Split'])\n",
    "#display(data_out_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_end.to_csv('data_out_end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Case</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitiv.</th>\n",
       "      <th>Specif.</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.866921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946860</td>\n",
       "      <td>0.227418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.565670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.637905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.348422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.840949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>-0.040322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.521282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.309975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.615741</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.239626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>0.705430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.223424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.553922</td>\n",
       "      <td>0.139617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.123753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.269443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653659</td>\n",
       "      <td>0.296118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.839024</td>\n",
       "      <td>0.365070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.304356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.678580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.652507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.833464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.876038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.769732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.713810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.758583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.882227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.778126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.802222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.412336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.670728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.921296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.489644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.551677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.705460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.729704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Case  threshold  Split  Accuracy  Sensitiv.   Specif.  \\\n",
       "0            0   1.0        5.0    0.0  0.967593   0.812500  0.994565   \n",
       "1            1   1.0        5.0    1.0  0.921296   0.333333  0.946860   \n",
       "2            2   1.0        5.0    2.0  0.777778   0.892857  0.653846   \n",
       "3            3   1.0        5.0    3.0  0.861111   0.980769  0.550000   \n",
       "4            4   1.0        5.0    4.0  0.736111   0.897260  0.400000   \n",
       "5            5   1.0        5.5    0.0  0.967593   0.807692  0.989474   \n",
       "6            6   1.0        5.5    1.0  0.921296   0.000000  0.952153   \n",
       "7            7   1.0        5.5    2.0  0.745370   0.863636  0.664062   \n",
       "8            8   1.0        5.5    3.0  0.546296   0.920635  0.392157   \n",
       "9            9   1.0        5.5    4.0  0.615741   0.801802  0.419048   \n",
       "10          10   1.0        6.0    0.0  0.953704   0.923077  0.955665   \n",
       "11          11   1.0        6.0    1.0  0.953704        NaN  0.953704   \n",
       "12          12   1.0        6.0    2.0  0.601852   1.000000  0.586538   \n",
       "13          13   1.0        6.0    3.0  0.564815   0.750000  0.553922   \n",
       "14          14   1.0        6.0    4.0  0.546296   0.625000  0.523810   \n",
       "15          15   1.0        6.5    0.0  0.930556        NaN  0.930556   \n",
       "16          16   1.0        6.5    1.0  0.962963        NaN  0.962963   \n",
       "17          17   1.0        6.5    2.0  0.754630        NaN  0.754630   \n",
       "18          18   1.0        6.5    3.0  0.745370   1.000000  0.738095   \n",
       "19          19   1.0        6.5    4.0  0.671296   1.000000  0.653659   \n",
       "20          20   1.0        7.0    0.0  0.953704        NaN  0.953704   \n",
       "21          21   1.0        7.0    1.0  0.981481        NaN  0.981481   \n",
       "22          22   1.0        7.0    2.0  0.884259        NaN  0.884259   \n",
       "23          23   1.0        7.0    3.0  0.837963   0.818182  0.839024   \n",
       "24          24   1.0        7.0    4.0  0.819444   1.000000  0.815166   \n",
       "25          25   2.2        5.0    0.0  0.916667   0.750000  0.945652   \n",
       "26          26   2.2        5.0    1.0  0.949074   0.909091  0.951220   \n",
       "27          27   2.2        5.0    2.0  0.916667   0.975410  0.840426   \n",
       "28          28   2.2        5.0    3.0  0.953704   1.000000  0.814815   \n",
       "29          29   2.2        5.0    4.0  0.898148   1.000000  0.681159   \n",
       "30          30   2.2        5.5    0.0  0.930556   0.741935  0.962162   \n",
       "31          31   2.2        5.5    1.0  0.976852   0.888889  0.980676   \n",
       "32          32   2.2        5.5    2.0  0.912037   0.982609  0.831683   \n",
       "33          33   2.2        5.5    3.0  0.953704   1.000000  0.827586   \n",
       "34          34   2.2        5.5    4.0  0.898148   1.000000  0.698630   \n",
       "35          35   2.2        6.0    0.0  0.967593   0.937500  0.970000   \n",
       "36          36   2.2        6.0    1.0  1.000000   1.000000  1.000000   \n",
       "37          37   2.2        6.0    2.0  0.990741        NaN  0.990741   \n",
       "38          38   2.2        6.0    3.0  0.763889   0.869565  0.751295   \n",
       "39          39   2.2        6.0    4.0  0.902778   0.923077  0.900000   \n",
       "40          40   2.2        6.5    0.0  0.944444        NaN  0.944444   \n",
       "41          41   2.2        6.5    1.0  1.000000   1.000000  1.000000   \n",
       "42          42   2.2        6.5    2.0  1.000000   1.000000  1.000000   \n",
       "43          43   2.2        6.5    3.0  0.921296   1.000000  0.919048   \n",
       "44          44   2.2        6.5    4.0  0.916667   1.000000  0.913043   \n",
       "45          45   2.2        7.0    0.0  0.981481        NaN  0.981481   \n",
       "46          46   2.2        7.0    1.0  1.000000   1.000000  1.000000   \n",
       "47          47   2.2        7.0    2.0  1.000000   1.000000  1.000000   \n",
       "48          48   2.2        7.0    3.0  0.995370   1.000000  0.995349   \n",
       "49          49   2.2        7.0    4.0  0.976852   1.000000  0.976190   \n",
       "\n",
       "         MCC  \n",
       "0   0.866921  \n",
       "1   0.227418  \n",
       "2   0.565670  \n",
       "3   0.637905  \n",
       "4   0.348422  \n",
       "5   0.840949  \n",
       "6  -0.040322  \n",
       "7   0.521282  \n",
       "8   0.309975  \n",
       "9   0.239626  \n",
       "10  0.705430  \n",
       "11       NaN  \n",
       "12  0.223424  \n",
       "13  0.139617  \n",
       "14  0.123753  \n",
       "15       NaN  \n",
       "16       NaN  \n",
       "17       NaN  \n",
       "18  0.269443  \n",
       "19  0.296118  \n",
       "20       NaN  \n",
       "21       NaN  \n",
       "22       NaN  \n",
       "23  0.365070  \n",
       "24  0.304356  \n",
       "25  0.678580  \n",
       "26  0.652507  \n",
       "27  0.833464  \n",
       "28  0.876038  \n",
       "29  0.769732  \n",
       "30  0.713810  \n",
       "31  0.758583  \n",
       "32  0.829982  \n",
       "33  0.882227  \n",
       "34  0.778126  \n",
       "35  0.802222  \n",
       "36  1.000000  \n",
       "37       NaN  \n",
       "38  0.412336  \n",
       "39  0.670728  \n",
       "40       NaN  \n",
       "41  1.000000  \n",
       "42  1.000000  \n",
       "43  0.489644  \n",
       "44  0.551677  \n",
       "45       NaN  \n",
       "46  1.000000  \n",
       "47  1.000000  \n",
       "48  0.705460  \n",
       "49  0.729704  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out_2 = pd.read_csv('/home/valeriia/bakalarka/bakalarka/data_out_end.csv')\n",
    "data_out_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
